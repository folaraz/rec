<!DOCTYPE html>
<!-- saved from url=(0067)https://www.kaggle.com/colinmorris/exploring-embeddings-with-gensim -->
<html lang="en" class="gr__kaggle_com"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Exploring Embeddings With Gensim | Kaggle</title>
    
    <meta name="robots" content="index, follow">
    <meta name="description" content="Download Open Datasets on 1000s of Projects + Share Projects on One Platform. Explore Popular Topics Like Government, Sports, Medicine, Fintech, Food, More. Flexible Data Ingestion.">
    <meta name="turbolinks-cache-control" content="no-cache">
                <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, minimum-scale=1.0">    <meta name="theme-color" content="#008ABC">
    <script type="text/javascript" async="" src="./Exploring Embeddings With Gensim _ Kaggle_files/koj6gxx6"></script><script type="text/javascript" async="" src="./Exploring Embeddings With Gensim _ Kaggle_files/js"></script><script type="text/javascript" async="" src="./Exploring Embeddings With Gensim _ Kaggle_files/analytics.js"></script><script src="./Exploring Embeddings With Gensim _ Kaggle_files/cb=gapi.loaded_0" async=""></script><script src="./Exploring Embeddings With Gensim _ Kaggle_files/inferredEvents.js" async=""></script><script src="./Exploring Embeddings With Gensim _ Kaggle_files/136809193586742" async=""></script><script async="" src="./Exploring Embeddings With Gensim _ Kaggle_files/fbevents.js"></script><script type="text/javascript">
        window["initialPageLoadStartTime"] = new Date().getTime();
    </script>
    <link rel="dns-prefetch" href="https://www.google-analytics.com/"><link rel="dns-prefetch" href="https://stats.g.doubleclick.net/"><link rel="dns-prefetch" href="https://js.intercomcdn.com/"><link rel="dns-prefetch" href="https://storage.googleapis.com/">
    <link href="https://www.kaggle.com/static/images/favicon.ico" rel="shortcut icon" type="image/x-icon">
    <link rel="manifest" href="https://www.kaggle.com/static/json/manifest.json">
    <link href="./Exploring Embeddings With Gensim _ Kaggle_files/css" rel="stylesheet" type="text/css">
    <link href="./Exploring Embeddings With Gensim _ Kaggle_files/icon" rel="stylesheet" type="text/css">
        <link rel="canonical" href="https://www.kaggle.com/colinmorris/exploring-embeddings-with-gensim">                    <link rel="stylesheet" type="text/css" href="./Exploring Embeddings With Gensim _ Kaggle_files/vendor.css">
        <link rel="stylesheet" type="text/css" href="./Exploring Embeddings With Gensim _ Kaggle_files/app.css">
    
    
 
        <script>
        try{(function(a,s,y,n,c,h,i,d,e){d=s.createElement("style");
        d.appendChild(s.createTextNode(""));s.head.appendChild(d);d=d.sheet;
        y=y.map(x => d.insertRule(x + "{ opacity: 0 !important }"));
        h.start=1*new Date;h.end=i=function(){y.forEach(x => x<d.cssRules.length ? d.deleteRule(x) : {})};
        (a[n]=a[n]||[]).hide=h;setTimeout(function(){i();h.end=null},c);h.timeout=c;
        })(window,document,['.site-header-react__nav'],'dataLayer',2000,{'GTM-52LNT9S':true});}catch{}
    </script><style></style>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());
        gtag('config', 'UA-12629138-1', {
            'optimize_id': 'GTM-52LNT9S',
            'displayFeaturesTask': null,
            'send_page_view': false
        });
    </script>
    <script async="" src="./Exploring Embeddings With Gensim _ Kaggle_files/js(1)"></script>

    
<script>
    !function(f,b,e,v,n,t,s)
    {if(f.fbq)return;n=f.fbq=function(){n.callMethod?
            n.callMethod.apply(n,arguments):n.queue.push(arguments)};
        if(!f._fbq)f._fbq=n;n.push=n;n.loaded=!0;n.version='2.0';
        n.queue=[];t=b.createElement(e);t.async=!0;
        t.src=v;s=b.getElementsByTagName(e)[0];
        s.parentNode.insertBefore(t,s)}(window,document,'script',
        'https://connect.facebook.net/en_US/fbevents.js');
    fbq("set", "autoConfig", "false", "136809193586742");
    fbq('init', '136809193586742'); 
    fbq('track', 'PageView');
</script>
<noscript>
    <img height="1" width="1" src="https://www.facebook.com/tr?id=136809193586742&ev=PageView&noscript=1"/>
</noscript>

<script>window.intercomSettings = {"app_id":"koj6gxx6","name":"folaraz","email":"folaraz11@gmail.com","user_hash":"6e641bcd63a7f407245a43915d0f0d46bad08f4d4c67fa5fa2235ff6dbdc3704","created_at":1484494417,"last_visit_date_at":1566156604,"status_id":2,"performance_tier":1,"user_name":"folaraz","display_name":"folaraz","is_admin":false,"experiment_group":1,"newsletter_subscriber":true,"competition_mailing_list_subscriber":true,"block_emails":false,"competitions_tier":1,"competitions_tier_attained_at":1563617594,"kernels_tier":1,"kernels_tier_attained_at":1563617594,"discussion_tier":1,"discussion_tier_attained_at":1563617594,"datasets_count":1,"last_dataset_created_at":1506670801,"last_new_dataset_visit_at":1485705903,"host_page_visits":11,"in_class_competitions_hosted_count":4,"last_hour_searches_count":0,"api_has_token":true,"api_has_requests":false,"api_token_created":1554793611};</script>        <script>(function () { var w = window; var ic = w.Intercom; if (typeof ic === "function") { ic('reattach_activator'); ic('update', intercomSettings); } else { var d = document; var i = function () { i.c(arguments) }; i.q = []; i.c = function (args) { i.q.push(args) }; w.Intercom = i; function l() { var s = d.createElement('script'); s.type = 'text/javascript'; s.async = true; s.src = 'https://widget.intercom.io/widget/koj6gxx6'; var x = d.getElementsByTagName('script')[0]; x.parentNode.insertBefore(s, x); } if (w.attachEvent) { w.attachEvent('onload', l); } else { w.addEventListener('load', l, false); } } })()</script>
    
    
    <meta name="twitter:card" content="summary">
    <meta name="twitter:site" content="@kaggledatasets">
    <meta name="og:url" content="https://kaggle.com/colinmorris/exploring-embeddings-with-gensim">
    <meta name="og:title" content="Exploring Embeddings With Gensim">
    <meta name="og:description" content="Using data from multiple data sources">
    <meta name="og:image" content="https://storage.googleapis.com/kaggle-avatars/thumbnails/473824-kg.jpg">


    
    

    
    
    
<script type="text/javascript">
    var Kaggle = Kaggle || {};

    Kaggle.Current = {
        userId: 868931,
        userProfileUrl: '/folaraz',
        userDisplayNameEscaped: 'folaraz',
        userThumbnailUrl: 'https://storage.googleapis.com/kaggle-avatars/thumbnails/868931-kg.jpg',
        userEmail: 'folaraz11@gmail.com',
        userIsPhoneVerified: true,
        userName: 'folaraz',
        tier: 'Contributor',
        antiForgeryToken: 'CfDJ8LdUzqlsSWBPr4Ce3rb9VL80BVp_To_mq9CzDdR8l5z2d2SkCEXz7H3HA_CtLKlxkcN45W1H4jGXQ1qXY1GJF-GO0VqN63LfufP-HjA4l6NgBxF1mtt7cz9sRPTJ3QrFTeyXJhq2B21ex8zT48u1P4T3I1IozqiUjE7HdYmyw-fRMg-pra1s1ju1yXpNTmawmA',
        isAnonymous: false,
        analyticsToken: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE1NjYxNTc1NDgsIlVzZXJJZCI6ODY4OTMxfQ.Gh68Hd9Vj_Bdi8LWM6yZVjeh6b8ie61feSbJ0S4rAo0',
        analyticsTokenExpiry: 15,
        internetKernelsEnabled: true,
        
        
        
        
        
        
        mdeImageUploader: true,
        
        
        
    }
        Kaggle.Current.log = function(){};
        Kaggle.Current.warn = function(){};

    var decodeUserDisplayName = function () {
        var escapedUserDisplayName = Kaggle.Current.userDisplayNameEscaped || "";
        try {
            var textVersion = new DOMParser().parseFromString(escapedUserDisplayName, "text/html").documentElement.textContent;
            if (textVersion) {
                return textVersion;
            }
        } catch(ex) {}
        return escapedUserDisplayName;
    }
    Kaggle.Current.userDisplayName = decodeUserDisplayName();
</script>

    

<script type="text/javascript">
    var Kaggle = Kaggle || {};
    Kaggle.PageMessages = [];
</script>

    
<script type="text/javascript">
/* <![CDATA[ */
goog_snippet_vars = function() {
    var w = window;
    w.google_conversion_id = 955616553;
    w.google_conversion_label = "QSjvCKDksHMQqZrWxwM";
    w.google_conversion_value = 0.00;
    w.google_conversion_currency = "USD";
    w.google_remarketing_only = false;
    w.google_conversion_language = "en";
    w.google_conversion_format = "3";
    w.google_conversion_color = "ffffff";
}
// DO NOT CHANGE THE CODE BELOW.
goog_report_conversion = function(url) {
    goog_snippet_vars();
    window.google_conversion_format = "3";
    var opt = new Object();
    opt.onload_callback = function() {
        if (typeof(url) != 'undefined') {
            window.location = url;
        }
    }
    var conv_handler = window['google_trackConversion'];
    if (typeof(conv_handler) == 'function') {
        conv_handler(opt);
    }
}
/* ]]> */
</script>
<script type="text/javascript" src="./Exploring Embeddings With Gensim _ Kaggle_files/f.txt">
</script>



        <script>window['useKaggleAnalytics'] = true;</script>

    <script src="./Exploring Embeddings With Gensim _ Kaggle_files/vendor.js" data-turbolinks-track="reload"></script>
    <script src="./Exploring Embeddings With Gensim _ Kaggle_files/app.js" data-turbolinks-track="reload"></script><style data-styled="" data-styled-version="4.3.2" id="kaggle-sc-1" data-turbolinks-permanent="true"></style><style data-styled="" data-styled-version="4.3.2" id="kaggle-sc-2" data-turbolinks-permanent="true"></style><style data-styled="" data-styled-version="4.3.2" id="kaggle-sc-3" data-turbolinks-permanent="true"></style><style data-emotion=""></style>
        <script>
            (function() {
                if ('serviceWorker' in navigator) {
                    navigator.serviceWorker.register("/static/assets/service-worker.js").then(function(reg) {
                        reg.onupdatefound = function() {
                            var installingWorker = reg.installing;
                            installingWorker.onstatechange = function() {
                                switch (installingWorker.state) {
                                case 'installed':
                                    if (navigator.serviceWorker.controller) {
                                        console.log('New or updated content is available.');
                                    } else {
                                        console.log('Content is now available offline!');
                                    }
                                    break;
                                case 'redundant':
                                    console.error('The installing service worker became redundant.');
                                    break;
                                }
                            };
                        };
                    }).catch(function(e) {
                      console.error('Error during service worker registration:', e);
                    });
                }
            })();
        </script>
    <script>
        function handleClientLoad() {
            try {
                gapi.load('client:auth2');
            } catch (e) {
                // In Opera, readystatechange is an unreliable detection of script load, causing
                // this function to be called before gapi exists on the window. The onload callback
                // is still called at the correct time, so the feature works as expected - it's
                // just generating noisy errors.
            }
        }
    </script>
    <script async="" defer="" src="./Exploring Embeddings With Gensim _ Kaggle_files/api.js" onload="this.googleApiOnLoad=function(){};handleClientLoad()" onreadystatechange="if (this.readyState === &#39;complete&#39;) this.googleApiOnLoad()" gapi_processed="true">
    </script>
            <script defer="" src="./Exploring Embeddings With Gensim _ Kaggle_files/stackdriver-errors-concat.min.js"></script>
        <script type="text/javascript">
            window.addEventListener('DOMContentLoaded', function () {
                var errorHandler = new StackdriverErrorReporter();
                errorHandler.start({
                    key: 'AIzaSyDANGXFHtSIVc51MIdGwg4mQFgm3oNrKoo',
                    projectId: 'kaggle-161607',
                    service: 'web-fe',
                    version: 'a3e6ca76aff7f1d0b82818a853dbc274ddafeec4',
                    context: { user: '868931' }
                });
            });
        </script>
<script charset="utf-8" src="./Exploring Embeddings With Gensim _ Kaggle_files/4.js"></script><style type="text/css">.MathJax_Hover_Frame {border-radius: .25em; -webkit-border-radius: .25em; -moz-border-radius: .25em; -khtml-border-radius: .25em; box-shadow: 0px 0px 15px #83A; -webkit-box-shadow: 0px 0px 15px #83A; -moz-box-shadow: 0px 0px 15px #83A; -khtml-box-shadow: 0px 0px 15px #83A; border: 1px solid #A6D ! important; display: inline-block; position: absolute}
.MathJax_Menu_Button .MathJax_Hover_Arrow {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 4px; -webkit-border-radius: 4px; -moz-border-radius: 4px; -khtml-border-radius: 4px; font-family: 'Courier New',Courier; font-size: 9px; color: #F0F0F0}
.MathJax_Menu_Button .MathJax_Hover_Arrow span {display: block; background-color: #AAA; border: 1px solid; border-radius: 3px; line-height: 0; padding: 4px}
.MathJax_Hover_Arrow:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_Hover_Arrow:hover span {background-color: #CCC!important}
</style><style type="text/css">#MathJax_About {position: fixed; left: 50%; width: auto; text-align: center; border: 3px outset; padding: 1em 2em; background-color: #DDDDDD; color: black; cursor: default; font-family: message-box; font-size: 120%; font-style: normal; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 15px; -webkit-border-radius: 15px; -moz-border-radius: 15px; -khtml-border-radius: 15px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_About.MathJax_MousePost {outline: none}
.MathJax_Menu {position: absolute; background-color: white; color: black; width: auto; padding: 5px 0px; border: 1px solid #CCCCCC; margin: 0; cursor: default; font: menu; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 5px; -webkit-border-radius: 5px; -moz-border-radius: 5px; -khtml-border-radius: 5px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
.MathJax_MenuItem {padding: 1px 2em; background: transparent}
.MathJax_MenuArrow {position: absolute; right: .5em; padding-top: .25em; color: #666666; font-size: .75em}
.MathJax_MenuActive .MathJax_MenuArrow {color: white}
.MathJax_MenuArrow.RTL {left: .5em; right: auto}
.MathJax_MenuCheck {position: absolute; left: .7em}
.MathJax_MenuCheck.RTL {right: .7em; left: auto}
.MathJax_MenuRadioCheck {position: absolute; left: .7em}
.MathJax_MenuRadioCheck.RTL {right: .7em; left: auto}
.MathJax_MenuLabel {padding: 1px 2em 3px 1.33em; font-style: italic}
.MathJax_MenuRule {border-top: 1px solid #DDDDDD; margin: 4px 3px}
.MathJax_MenuDisabled {color: GrayText}
.MathJax_MenuActive {background-color: #606872; color: white}
.MathJax_MenuDisabled:focus, .MathJax_MenuLabel:focus {background-color: #E8E8E8}
.MathJax_ContextMenu:focus {outline: none}
.MathJax_ContextMenu .MathJax_MenuItem:focus {outline: none}
#MathJax_AboutClose {top: .2em; right: .2em}
.MathJax_Menu .MathJax_MenuClose {top: -10px; left: -10px}
.MathJax_MenuClose {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; font-family: 'Courier New',Courier; font-size: 24px; color: #F0F0F0}
.MathJax_MenuClose span {display: block; background-color: #AAA; border: 1.5px solid; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; line-height: 0; padding: 8px 0 6px}
.MathJax_MenuClose:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_MenuClose:hover span {background-color: #CCC!important}
.MathJax_MenuClose:hover:focus {outline: none}
</style><style type="text/css">.MathJax_Preview .MJXf-math {color: inherit!important}
</style><style type="text/css">.MJX_Assistive_MathML {position: absolute!important; top: 0; left: 0; clip: rect(1px, 1px, 1px, 1px); padding: 1px 0 0 0!important; border: 0!important; height: 1px!important; width: 1px!important; overflow: hidden!important; display: block!important; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none}
.MJX_Assistive_MathML.MJX_Assistive_MathML_Block {width: 100%!important}
</style><style type="text/css">#MathJax_Zoom {position: absolute; background-color: #F0F0F0; overflow: auto; display: block; z-index: 301; padding: .5em; border: 1px solid black; margin: 0; font-weight: normal; font-style: normal; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; -webkit-box-sizing: content-box; -moz-box-sizing: content-box; box-sizing: content-box; box-shadow: 5px 5px 15px #AAAAAA; -webkit-box-shadow: 5px 5px 15px #AAAAAA; -moz-box-shadow: 5px 5px 15px #AAAAAA; -khtml-box-shadow: 5px 5px 15px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_ZoomOverlay {position: absolute; left: 0; top: 0; z-index: 300; display: inline-block; width: 100%; height: 100%; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
#MathJax_ZoomFrame {position: relative; display: inline-block; height: 0; width: 0}
#MathJax_ZoomEventTrap {position: absolute; left: 0; top: 0; z-index: 302; display: inline-block; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
</style><style type="text/css">.MathJax_Preview {color: #888}
#MathJax_Message {position: fixed; left: 1em; bottom: 1.5em; background-color: #E6E6E6; border: 1px solid #959595; margin: 0px; padding: 2px 8px; z-index: 102; color: black; font-size: 80%; width: auto; white-space: nowrap}
#MathJax_MSIE_Frame {position: absolute; top: 0; left: 0; width: 0px; z-index: 101; border: 0px; margin: 0px; padding: 0px}
.MathJax_Error {color: #CC0000; font-style: italic}
</style><style type="text/css">.MJXp-script {font-size: .8em}
.MJXp-right {-webkit-transform-origin: right; -moz-transform-origin: right; -ms-transform-origin: right; -o-transform-origin: right; transform-origin: right}
.MJXp-bold {font-weight: bold}
.MJXp-italic {font-style: italic}
.MJXp-scr {font-family: MathJax_Script,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-frak {font-family: MathJax_Fraktur,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-sf {font-family: MathJax_SansSerif,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-cal {font-family: MathJax_Caligraphic,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-mono {font-family: MathJax_Typewriter,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-largeop {font-size: 150%}
.MJXp-largeop.MJXp-int {vertical-align: -.2em}
.MJXp-math {display: inline-block; line-height: 1.2; text-indent: 0; font-family: 'Times New Roman',Times,STIXGeneral,serif; white-space: nowrap; border-collapse: collapse}
.MJXp-display {display: block; text-align: center; margin: 1em 0}
.MJXp-math span {display: inline-block}
.MJXp-box {display: block!important; text-align: center}
.MJXp-box:after {content: " "}
.MJXp-rule {display: block!important; margin-top: .1em}
.MJXp-char {display: block!important}
.MJXp-mo {margin: 0 .15em}
.MJXp-mfrac {margin: 0 .125em; vertical-align: .25em}
.MJXp-denom {display: inline-table!important; width: 100%}
.MJXp-denom > * {display: table-row!important}
.MJXp-surd {vertical-align: top}
.MJXp-surd > * {display: block!important}
.MJXp-script-box > *  {display: table!important; height: 50%}
.MJXp-script-box > * > * {display: table-cell!important; vertical-align: top}
.MJXp-script-box > *:last-child > * {vertical-align: bottom}
.MJXp-script-box > * > * > * {display: block!important}
.MJXp-mphantom {visibility: hidden}
.MJXp-munderover {display: inline-table!important}
.MJXp-over {display: inline-block!important; text-align: center}
.MJXp-over > * {display: block!important}
.MJXp-munderover > * {display: table-row!important}
.MJXp-mtable {vertical-align: .25em; margin: 0 .125em}
.MJXp-mtable > * {display: inline-table!important; vertical-align: middle}
.MJXp-mtr {display: table-row!important}
.MJXp-mtd {display: table-cell!important; text-align: center; padding: .5em 0 0 .5em}
.MJXp-mtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-mlabeledtr {display: table-row!important}
.MJXp-mlabeledtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mlabeledtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MJXp-scale0 {-webkit-transform: scaleX(.0); -moz-transform: scaleX(.0); -ms-transform: scaleX(.0); -o-transform: scaleX(.0); transform: scaleX(.0)}
.MJXp-scale1 {-webkit-transform: scaleX(.1); -moz-transform: scaleX(.1); -ms-transform: scaleX(.1); -o-transform: scaleX(.1); transform: scaleX(.1)}
.MJXp-scale2 {-webkit-transform: scaleX(.2); -moz-transform: scaleX(.2); -ms-transform: scaleX(.2); -o-transform: scaleX(.2); transform: scaleX(.2)}
.MJXp-scale3 {-webkit-transform: scaleX(.3); -moz-transform: scaleX(.3); -ms-transform: scaleX(.3); -o-transform: scaleX(.3); transform: scaleX(.3)}
.MJXp-scale4 {-webkit-transform: scaleX(.4); -moz-transform: scaleX(.4); -ms-transform: scaleX(.4); -o-transform: scaleX(.4); transform: scaleX(.4)}
.MJXp-scale5 {-webkit-transform: scaleX(.5); -moz-transform: scaleX(.5); -ms-transform: scaleX(.5); -o-transform: scaleX(.5); transform: scaleX(.5)}
.MJXp-scale6 {-webkit-transform: scaleX(.6); -moz-transform: scaleX(.6); -ms-transform: scaleX(.6); -o-transform: scaleX(.6); transform: scaleX(.6)}
.MJXp-scale7 {-webkit-transform: scaleX(.7); -moz-transform: scaleX(.7); -ms-transform: scaleX(.7); -o-transform: scaleX(.7); transform: scaleX(.7)}
.MJXp-scale8 {-webkit-transform: scaleX(.8); -moz-transform: scaleX(.8); -ms-transform: scaleX(.8); -o-transform: scaleX(.8); transform: scaleX(.8)}
.MJXp-scale9 {-webkit-transform: scaleX(.9); -moz-transform: scaleX(.9); -ms-transform: scaleX(.9); -o-transform: scaleX(.9); transform: scaleX(.9)}
.MathJax_PHTML .noError {vertical-align: ; font-size: 90%; text-align: left; color: black; padding: 1px 3px; border: 1px solid}
</style></head>
<body data-turbolinks="true" data-gr-c-s-loaded="true"><div id="MathJax_Message" style="display: none;"></div>
    <main>
        






<div class="site-layout">
        <div class="site-layout__header">
            <div data-component-name="SiteHeaderContainer" style="display: flex; flex-direction: column; flex: 1 0 auto;"><div style="--mdc-theme-on-primary:#fff; --mdc-theme-on-surface:rgba(0, 0, 0, 0.87); --mdc-theme-text-primary-on-background:rgba(0, 0, 0, 0.87); --mdc-theme-text-secondary-on-background:rgba(0, 0, 0, 0.54); --mdc-theme-text-hint-on-background:rgba(0, 0, 0, 0.38); --mdc-theme-text-disabled-on-background:rgba(0, 0, 0, 0.38); --mdc-theme-text-icon-on-background:rgba(0, 0, 0, 0.38); --mdc-theme-primary:#20BEFF; --mdc-theme-error:#F58B8A; --mdc-theme-background:#F8F8F8; --mdc-theme-surface:#F8F8F8; --mdc-theme-primary-bg:#20BEFF; --mdc-theme-secondary-bg:#919294;"><div class="site-header-react"><div class="site-header-react__wrapper-cookies-header"><div class="site-header-react__container"><div class="site-header-react__content"><div class="site-header-react__logo"><a href="https://www.kaggle.com/"><img alt="Kaggle" src="./Exploring Embeddings With Gensim _ Kaggle_files/site-logo.png"></a></div><div class="site-header-react__quick-search"><div class="quick-search undefined quick-search--dark false undefined"><div class="quick-search__search-box-container"><input aria-label="Site search" class="quick-search__search-box " type="text" placeholder="Search"><div class="quick-search__button"><i class="fa fa-search"></i></div></div></div></div><nav class="site-header-react__nav"><ol class="SiteHeader_SiteHeaderNavList-sc-fru52l btMbfT"><li class="site-header-react__nav-item site-header-react__nav-item--first"><a id="site-header-competitions__a" href="https://www.kaggle.com/competitions">Competitions</a></li><li class="site-header-react__nav-item "><a id="site-header-datasets__a" href="https://www.kaggle.com/datasets">Datasets</a></li><li class="site-header-react__nav-item "><a id="site-header-notebooks__a" href="https://www.kaggle.com/kernels">Notebooks</a></li><li class="site-header-react__nav-item "><a id="site-header-discussion__a" href="https://www.kaggle.com/discussion">Discussion</a></li><li class="site-header-react__nav-item "><a id="site-header-courses__a" href="https://www.kaggle.com/learn">Courses</a></li><li class="site-header-react__nav-item"><a class="site-header-react__extra-link" title="More" style=""><svg class="site-header-react__nav-ellipsis" width="18px" height="4px" viewBox="0 0 18 4"><g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><path d="M16,4 C14.8954305,4 14,3.1045695 14,2 C14,0.8954305 14.8954305,0 16,0 C17.1045695,0 18,0.8954305 18,2 C18,3.1045695 17.1045695,4 16,4 Z M9,4 C7.8954305,4 7,3.1045695 7,2 C7,0.8954305 7.8954305,0 9,0 C10.1045695,0 11,0.8954305 11,2 C11,3.1045695 10.1045695,4 9,4 Z M2,4 C0.8954305,4 0,3.1045695 0,2 C0,0.8954305 0.8954305,0 2,0 C3.1045695,0 4,0.8954305 4,2 C4,3.1045695 3.1045695,4 2,4 Z" fill="#FFFFFF"></path></g></svg></a></li></ol></nav><div class="NotificationContainer_NotificationContainerWrapper-sc-bb4fan kMXxed"><span class="tooltip-container NotificationContainer_NotificationTooltipWrapper-sc-1jdjwer TZodN" data-tooltip="Notifications"><div class="NotificationIcon_NotificationIconWrapper-sc-3rbk7d dBubSX"><div class="NotificationIcon_NotificationIconIcon-sc-wpy2fb cdXHpW"><span name="bell" class="fa fa-bell"></span></div><div class="NotificationIcon_UnviewedCounterWrapper-sc-qoeqza LJMuf"><div class="NotificationIcon_UnviewedCounterText-sc-ifrp6v bhudHX">1</div></div></div></span><div></div></div><div class="site-header-react__user"><span class="tooltip-container" data-tooltip="Your profile"><div class="site-header-react__user--logged-in"><ul><li class="site-header-react__user-avatar"><img src="./Exploring Embeddings With Gensim _ Kaggle_files/868931-kg.jpg"></li></ul></div></span></div></div></div></div></div></div></div><script>var Kaggle=window.Kaggle||{};Kaggle.State=Kaggle.State||[];Kaggle.State.push({});performance && performance.mark && performance.mark("SiteHeaderContainer.componentCouldBootstrap");</script>
        </div>

    <div class="site-layout__main-content">
        

<div data-component-name="KernelViewer" style="display: flex; flex-direction: column; flex: 1 0 auto;"><div style="--mdc-theme-on-primary:#fff; --mdc-theme-on-surface:rgba(0, 0, 0, 0.87); --mdc-theme-text-primary-on-background:rgba(0, 0, 0, 0.87); --mdc-theme-text-secondary-on-background:rgba(0, 0, 0, 0.54); --mdc-theme-text-hint-on-background:rgba(0, 0, 0, 0.38); --mdc-theme-text-disabled-on-background:rgba(0, 0, 0, 0.38); --mdc-theme-text-icon-on-background:rgba(0, 0, 0, 0.38); --mdc-theme-primary:#20BEFF; --mdc-theme-error:#F58B8A; --mdc-theme-background:#F8F8F8; --mdc-theme-surface:#F8F8F8; --mdc-theme-primary-bg:#20BEFF; --mdc-theme-secondary-bg:#919294;"><div><div id="kernel-header-wrapper" class="KernelViewer_HeaderWrapper-sc-ohc1yt sDEXm" style="top: -1px;"><div class="sc-buGlAa crIovC"></div></div><div class="KernelViewer_ViewerContent-sc-c2nrua fxgEVS"><div class="kernel-viewer"><span class="KernelViewer_NavigationSidebarWrapper-sc-56cp8f jJbHsV"><div class="KernelViewerContext_FullNavigationMenu-sc-1n0pzuj KernelViewerContext_LinklessNavigationMenu-sc-1hmbdku haBfAe"><div class="navbox__container"><div class="navbox__nav-wrapper"><nav class="navbox__nav"><a class="navbox__nav-item--selected" href="https://www.kaggle.com/colinmorris/exploring-embeddings-with-gensim/notebook" title="Notebook">Notebook</a><div class="navbox__page"><span class="KernelViewerContext_ContentsMenu-sc-8en2wv igjpFC"><div class="navbox__container"><div class="navbox__nav-wrapper"><nav class="navbox__nav"><a class="navbox__nav-item--selected-with-bar" href="https://www.kaggle.com/colinmorris/exploring-embeddings-with-gensim#Looking-up-embeddings" title="">Looking up embeddings</a><div class="navbox__page"></div><a class="navbox__nav-item" href="https://www.kaggle.com/colinmorris/exploring-embeddings-with-gensim#Exploring-embeddings-with-Gensim" title="">Exploring embeddings with Gensim</a><a class="navbox__nav-item" href="https://www.kaggle.com/colinmorris/exploring-embeddings-with-gensim#Semantic-vector-math" title="">Semantic vector math</a><a class="navbox__nav-item" href="https://www.kaggle.com/colinmorris/exploring-embeddings-with-gensim#Your-turn!" title="">Your turn!</a></nav></div></div></span></div><a class="navbox__nav-item" href="https://www.kaggle.com/colinmorris/exploring-embeddings-with-gensim/data" title="Data">Data</a><a class="navbox__nav-item" href="https://www.kaggle.com/colinmorris/exploring-embeddings-with-gensim/comments" title="Comments">Comments</a></nav></div></div></div></span><div class="kernel-viewer__container"><div class="kernel-viewer__pane-container" id="kernel-viewer__pane-container"><div id="notebook"><div><div class="kernel-notebook-pane" style="display: block;"><div class="content-box"><div><div class="content-box__title-bar"><div class="ContentBox_Title-sc-6fbrxj iCvEyH" style="line-height: 46px;">Notebook</div></div></div><div class="content-box__content-section"><div class="kernel-notebook-pane__container"><iframe id="rendered-kernel-content" src="./Exploring Embeddings With Gensim _ Kaggle_files/__results__.html" scrolling="no" title="Main Kernel Content" style="height: 10065px; display: block;"></iframe><div class="kernel-notebook-pane__loading" style="display: none;"><div class="Spinner_SpinnerContainer-sc-fllvzl cBVAFE"><i class="fa fa-circle-o-notch fa-spin fa-2x"></i></div></div></div></div></div></div><div class="kernel-code-pane__subtitle" id="notebook-pane-license-info">This kernel has been released under the <a href="http://www.apache.org/licenses/LICENSE-2.0">Apache 2.0</a> open source license.</div><div class="upvote-suggestion upvote-suggestion__kernel"><div class="upvote-suggestion__text"><div class="upvote-suggestion__main-text">Did you find this Kernel useful?</div><div class="upvote-suggestion__sub-text">Show your appreciation with an upvote</div></div><div class="upvote-suggestion__button"><div class="vote-button__container "><div class="vote-button vote-button--enabled"><div class="vote-button__button vote-button__button--up vb-upvote"><span class="fa fa-caret-up"></span></div><div class="vote-button__button vote-button__button--up vote-button__vote-count-container"><span class="vote-button__vote-count">31</span></div><div class="vote-button__button-placeholder"></div></div></div></div><div class="upvote-suggestion__voters"><div class="upvote-suggestion__voter upvote-suggestion__voter-top"><span class="tooltip-container" data-tooltip="Abo Sol" data-tooltip-size="small"><a href="https://www.kaggle.com/abosol" class="upvote-suggestion__voter-link"><img src="./Exploring Embeddings With Gensim _ Kaggle_files/110108-kg.JPG" alt="Abo Sol" class="upvote-suggestion__voter-img"></a></span></div><div class="upvote-suggestion__voter upvote-suggestion__voter-top"><span class="tooltip-container" data-tooltip="Sakares Saengkaew" data-tooltip-size="small"><a href="https://www.kaggle.com/sakares" class="upvote-suggestion__voter-link"><img src="./Exploring Embeddings With Gensim _ Kaggle_files/131914-kg.jpg" alt="Sakares Saengkaew" class="upvote-suggestion__voter-img"></a></span></div><div class="upvote-suggestion__voter upvote-suggestion__voter-top"><span class="tooltip-container" data-tooltip="CXQ" data-tooltip-size="small"><a href="https://www.kaggle.com/caoxiaoqing" class="upvote-suggestion__voter-link"><img src="./Exploring Embeddings With Gensim _ Kaggle_files/201481-fb.jpg" alt="CXQ" class="upvote-suggestion__voter-img"></a></span></div><div class="upvote-suggestion__voter upvote-suggestion__voter-more"><span class="tooltip-container" data-tooltip="Donlo Wong" data-tooltip-size="small"><a href="https://www.kaggle.com/cfwongaf" class="upvote-suggestion__voter-link"><img src="./Exploring Embeddings With Gensim _ Kaggle_files/default-thumb.png" alt="Donlo Wong" class="upvote-suggestion__voter-img"></a></span></div><div class="upvote-suggestion__voter upvote-suggestion__voter-more"><span class="tooltip-container" data-tooltip="Larry" data-tooltip-size="small"><a href="https://www.kaggle.com/larry0220" class="upvote-suggestion__voter-link"><img src="./Exploring Embeddings With Gensim _ Kaggle_files/455304-fb.jpg" alt="Larry" class="upvote-suggestion__voter-img"></a></span></div><div class="upvote-suggestion__voter upvote-suggestion__voter-more"><span class="tooltip-container" data-tooltip="Mileta" data-tooltip-size="small"><a href="https://www.kaggle.com/mileta1976" class="upvote-suggestion__voter-link"><img src="./Exploring Embeddings With Gensim _ Kaggle_files/default-thumb.png" alt="Mileta" class="upvote-suggestion__voter-img"></a></span></div><div class="upvote-suggestion__voter upvote-suggestion__voter-more"><span class="tooltip-container" data-tooltip="keetar" data-tooltip-size="small"><a href="https://www.kaggle.com/keetar" class="upvote-suggestion__voter-link"><img src="./Exploring Embeddings With Gensim _ Kaggle_files/default-thumb.png" alt="keetar" class="upvote-suggestion__voter-img"></a></span></div><div class="upvote-suggestion__voter upvote-suggestion__voter-more"><span class="tooltip-container" data-tooltip="little_ordinary" data-tooltip-size="small"><a href="https://www.kaggle.com/blacksteed" class="upvote-suggestion__voter-link"><img src="./Exploring Embeddings With Gensim _ Kaggle_files/default-thumb.png" alt="little_ordinary" class="upvote-suggestion__voter-img"></a></span></div><div class="upvote-suggestion__voter upvote-suggestion__voter-more"><span class="tooltip-container" data-tooltip="Nick Brooks" data-tooltip-size="small"><a href="https://www.kaggle.com/nicapotato" class="upvote-suggestion__voter-link"><img src="./Exploring Embeddings With Gensim _ Kaggle_files/866788-kg.jpg" alt="Nick Brooks" class="upvote-suggestion__voter-img"></a></span></div><div class="upvote-suggestion__voter upvote-suggestion__voter-more"><span class="tooltip-container" data-tooltip="Gabriel Majeri" data-tooltip-size="small"><a href="https://www.kaggle.com/gabrielmajeri" class="upvote-suggestion__voter-link"><img src="./Exploring Embeddings With Gensim _ Kaggle_files/1270725-gr.jpg" alt="Gabriel Majeri" class="upvote-suggestion__voter-img"></a></span></div><div class="upvote-suggestion__voter upvote-suggestion__voter-other"><span class="tooltip-container" data-tooltip="Michal Zurek" data-tooltip-size="small"><a href="https://www.kaggle.com/michal777" class="upvote-suggestion__voter-link"><img src="./Exploring Embeddings With Gensim _ Kaggle_files/1360536-gr.jpg" alt="Michal Zurek" class="upvote-suggestion__voter-img"></a></span></div><div class="upvote-suggestion__voter upvote-suggestion__voter-other"><span class="tooltip-container" data-tooltip="Hiep Nguyen" data-tooltip-size="small"><a href="https://www.kaggle.com/nvhbk16k53" class="upvote-suggestion__voter-link"><img src="./Exploring Embeddings With Gensim _ Kaggle_files/1427069-kg.jpg" alt="Hiep Nguyen" class="upvote-suggestion__voter-img"></a></span></div><div class="upvote-suggestion__voter upvote-suggestion__voter-other"><span class="tooltip-container" data-tooltip="Akash Ravichandran" data-tooltip-size="small"><a href="https://www.kaggle.com/akashravichandran" class="upvote-suggestion__voter-link"><img src="./Exploring Embeddings With Gensim _ Kaggle_files/1449054-kg.jpg" alt="Akash Ravichandran" class="upvote-suggestion__voter-img"></a></span></div><div class="upvote-suggestion__voter upvote-suggestion__voter-other"><span class="tooltip-container" data-tooltip="Fazil T" data-tooltip-size="small"><a href="https://www.kaggle.com/fazilbtopal" class="upvote-suggestion__voter-link"><img src="./Exploring Embeddings With Gensim _ Kaggle_files/1559714-kg.jpg" alt="Fazil T" class="upvote-suggestion__voter-img"></a></span></div><div class="upvote-suggestion__voter upvote-suggestion__voter-other"><span class="tooltip-container" data-tooltip="Nicholas Buhagiar" data-tooltip-size="small"><a href="https://www.kaggle.com/nbuhagiar" class="upvote-suggestion__voter-link"><img src="./Exploring Embeddings With Gensim _ Kaggle_files/1621143-kg.jpg" alt="Nicholas Buhagiar" class="upvote-suggestion__voter-img"></a></span></div></div></div></div></div></div></div><div class="KernelViewer_EmptyColumn-sc-bggm6s hnmdWt"></div></div></div></div></div></div><script>var Kaggle=window.Kaggle||{};Kaggle.State=Kaggle.State||[];Kaggle.State.push({"kernel":{"id":1598892,"title":"Exploring Embeddings With Gensim","forkParent":null,"currentRunId":6375458,"mostRecentRunId":6375458,"url":"/colinmorris/exploring-embeddings-with-gensim","tags":[],"commentCount":0,"upvoteCount":31,"viewCount":3947,"forkCount":54,"bestPublicScore":null,"author":{"id":473824,"displayName":"ColinMorris","email":null,"editedEmail":null,"editedEmailCode":null,"userName":"colinmorris","thumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/473824-kg.jpg","profileUrl":"/colinmorris","registerDate":"0001-01-01T00:00:00Z","lastVisitDate":"0001-01-01T00:00:00Z","statusId":0,"performanceTier":3,"userRoles":null,"userLogins":null,"groupIds":null,"duplicateUsers":null,"hasPhoneVerifications":false,"failedNerdchas":0,"hasPendingNerdcha":false,"deleteRequests":null,"userAttributes":null,"isAdmin":false,"isTvc":false,"isKaggleBot":false,"isAdminOrTvc":false,"isAnonymous":false,"canAct":false,"canBeSeen":false,"thumbnailName":null,"activationCode":"00000000-0000-0000-0000-000000000000","isPhoneVerified":false},"isPrivate":false,"updatedTime":"2018-10-11T00:04:59.9866667Z","selfLink":"/kernels/1598892","pinnedDockerImageVersionId":null,"isLanguageTemplate":false,"medal":"bronze","topicId":79348,"readGroupId":19627,"writeGroupId":22336,"slug":"exploring-embeddings-with-gensim"},"kernelBlob":{"id":77057265,"settings":{"dockerImageVersionId":null,"dataSources":[{"sourceType":"KernelVersion","sourceId":6373076,"databundleVersionId":null,"mountSlug":null},{"sourceType":"KernelVersion","sourceId":6373082,"databundleVersionId":null,"mountSlug":null}],"sourceType":"notebook","language":"python","isGpuEnabled":false,"isInternetEnabled":false},"source":"{\u0022cells\u0022: [{\u0022cell_type\u0022: \u0022markdown\u0022, \u0022source\u0022: [\u0022Earlier we trained a model to predict the ratings users would give to movies using a network with embeddings learned for each movie and user. Embeddings are powerful! But how do they actually work? \\n\u0022, \u0022\\n\u0022, \u0022Previously, I claimed that embeddings capture the \u0027meaning\u0027 of the objects they represent, and discover useful latent structure. Let\u0027s put that to the test!\\n\u0022, \u0022\\n\u0022, \u0022# Looking up embeddings\\n\u0022, \u0022\\n\u0022, \u0022Let\u0027s load a model we trained earlier so we can investigate the embedding weights that it learned.\u0022], \u0022metadata\u0022: {}}, {\u0022cell_type\u0022: \u0022code\u0022, \u0022execution_count\u0022: null, \u0022metadata\u0022: {}, \u0022outputs\u0022: [], \u0022source\u0022: [\u0022import os\\n\u0022, \u0022\\n\u0022, \u0022import numpy as np\\n\u0022, \u0022import pandas as pd\\n\u0022, \u0022from matplotlib import pyplot as plt\\n\u0022, \u0022import tensorflow as tf\\n\u0022, \u0022from tensorflow import keras\\n\u0022, \u0022\\n\u0022, \u0022input_dir = \u0027../input/movielens-preprocessing\u0027\\n\u0022, \u0022model_dir = \u0027../input/movielens-spiffy-model\u0027\\n\u0022, \u0022model_path = os.path.join(model_dir, \u0027movie_svd_model_32.h5\u0027)\\n\u0022, \u0022model = keras.models.load_model(model_path)\u0022]}, {\u0022cell_type\u0022: \u0022markdown\u0022, \u0022source\u0022: [\u0022The embedding weights are part of the model\u0027s internals, so we\u0027ll have to do a bit of digging around to access them. We\u0027ll grab the layer responsible for embedding movies, and use the `get_weights()` method to get its learned weights.\u0022], \u0022metadata\u0022: {}}, {\u0022cell_type\u0022: \u0022code\u0022, \u0022execution_count\u0022: null, \u0022metadata\u0022: {}, \u0022outputs\u0022: [], \u0022source\u0022: [\u0022emb_layer = model.get_layer(\u0027movie_embedding\u0027)\\n\u0022, \u0022(w,) = emb_layer.get_weights()\\n\u0022, \u0022w.shape\u0022]}, {\u0022cell_type\u0022: \u0022markdown\u0022, \u0022source\u0022: [\u0022Our weight matrix has 26,744 rows for that many movies. Each row is 32 numbers - the size of our movie embeddings.\\n\u0022, \u0022\\n\u0022, \u0022Let\u0027s look at an example movie vector:\u0022], \u0022metadata\u0022: {}}, {\u0022cell_type\u0022: \u0022code\u0022, \u0022execution_count\u0022: null, \u0022metadata\u0022: {}, \u0022outputs\u0022: [], \u0022source\u0022: [\u0022w[0]\u0022]}, {\u0022cell_type\u0022: \u0022markdown\u0022, \u0022source\u0022: [\u0022What movie is this the embedding of? Let\u0027s load up our dataframe of movie metadata.\u0022], \u0022metadata\u0022: {}}, {\u0022cell_type\u0022: \u0022code\u0022, \u0022execution_count\u0022: null, \u0022metadata\u0022: {}, \u0022outputs\u0022: [], \u0022source\u0022: [\u0022movies_path = os.path.join(input_dir, \u0027movie.csv\u0027)\\n\u0022, \u0022movies_df = pd.read_csv(movies_path, index_col=0)\\n\u0022, \u0022movies_df.head()\u0022]}, {\u0022cell_type\u0022: \u0022markdown\u0022, \u0022source\u0022: [\u0022Of course, it\u0027s *Toy Story*! I should have recognized that vector anywhere.\\n\u0022, \u0022\\n\u0022, \u0022Okay, I\u0027m being facetious. It\u0027s hard to make anything of these vectors at this point. We never directed the model about how to use any particular embedding dimension. We left it alone to learn whatever representation it found useful.\\n\u0022, \u0022\\n\u0022, \u0022So how do we check whether these representations are sane and coherent?\\n\u0022, \u0022\\n\u0022, \u0022## Vector similarity\\n\u0022, \u0022\\n\u0022, \u0022A simple way to test this is to look at how close or distant pairs of movies are in the embedding space. Embeddings can be thought of as a smart distance metric. If our embedding matrix is any good, it should map similar movies (like *Toy Story* and *Shrek*) to similar vectors.\u0022], \u0022metadata\u0022: {}}, {\u0022cell_type\u0022: \u0022code\u0022, \u0022execution_count\u0022: null, \u0022metadata\u0022: {}, \u0022outputs\u0022: [], \u0022source\u0022: [\u0022i_toy_story = 0\\n\u0022, \u0022i_shrek = movies_df.loc[\\n\u0022, \u0022    movies_df.title == \u0027Shrek\u0027,\\n\u0022, \u0022    \u0027movieId\u0027\\n\u0022, \u0022].iloc[0]\\n\u0022, \u0022\\n\u0022, \u0022toy_story_vec = w[i_toy_story]\\n\u0022, \u0022shrek_vec = w[i_shrek]\\n\u0022, \u0022\\n\u0022, \u0022print(\\n\u0022, \u0022    toy_story_vec,\\n\u0022, \u0022    shrek_vec,\\n\u0022, \u0022    sep=\u0027\\\\n\u0027,\\n\u0022, \u0022)\u0022]}, {\u0022cell_type\u0022: \u0022markdown\u0022, \u0022source\u0022: [\u0022Comparing dimension-by-dimension, these look vaguely similar. If we wanted to assign a single number to their similarity, we could calculate the euclidean distance between these two vectors. (This is our conventional \u0027as the crow flies\u0027 notion of distance between two points. Easy to grok in 1, 2, or 3 dimensions. Mathematically, we can also extend it to 32 dimensions, though good luck visualizing it.)\u0022], \u0022metadata\u0022: {}}, {\u0022cell_type\u0022: \u0022code\u0022, \u0022execution_count\u0022: null, \u0022metadata\u0022: {}, \u0022outputs\u0022: [], \u0022source\u0022: [\u0022from scipy.spatial import distance\\n\u0022, \u0022\\n\u0022, \u0022distance.euclidean(toy_story_vec, shrek_vec)\u0022]}, {\u0022cell_type\u0022: \u0022markdown\u0022, \u0022source\u0022: [\u0022How does this compare to a pair of movies that we would think of as very different?\u0022], \u0022metadata\u0022: {}}, {\u0022cell_type\u0022: \u0022code\u0022, \u0022execution_count\u0022: null, \u0022metadata\u0022: {}, \u0022outputs\u0022: [], \u0022source\u0022: [\u0022i_exorcist = movies_df.loc[\\n\u0022, \u0022    movies_df.title == \u0027The Exorcist\u0027,\\n\u0022, \u0022    \u0027movieId\u0027\\n\u0022, \u0022].iloc[0]\\n\u0022, \u0022\\n\u0022, \u0022exorcist_vec = w[i_exorcist]\\n\u0022, \u0022\\n\u0022, \u0022distance.euclidean(toy_story_vec, exorcist_vec)\u0022]}, {\u0022cell_type\u0022: \u0022markdown\u0022, \u0022source\u0022: [\u0022As expected, much further apart.\\n\u0022, \u0022\\n\u0022, \u0022## Cosine Distance\\n\u0022, \u0022\\n\u0022, \u0022If you check out [the docs for the `scipy.spatial` module](https://docs.scipy.org/doc/scipy-0.14.0/reference/spatial.distance.html), you\u0027ll see there are actually a *lot* of different measures of distance that people use for different tasks.\\n\u0022, \u0022\\n\u0022, \u0022When judging the similarity of embeddings, it\u0027s more common to use [cosine similarity](https://en.wikipedia.org/wiki/Cosine_similarity).\\n\u0022, \u0022\\n\u0022, \u0022In brief, the cosine similarity of two vectors ranges from -1 to 1, and is a function of the *angle* between the vectors. If two vectors point in the same direction, their cosine similarity is 1. If they point in opposite directions, it\u0027s -1. If they\u0027re orthogonal (i.e. at right angles), their cosine similarity is 0.\\n\u0022, \u0022\\n\u0022, \u0022Cosine distance is just defined as 1 minus the cosine similarity (and therefore ranges from 0 to 2).\\n\u0022, \u0022\\n\u0022, \u0022Let\u0027s calculate a couple cosine distances between movie vectors:\u0022], \u0022metadata\u0022: {}}, {\u0022cell_type\u0022: \u0022code\u0022, \u0022execution_count\u0022: null, \u0022metadata\u0022: {}, \u0022outputs\u0022: [], \u0022source\u0022: [\u0022print(\\n\u0022, \u0022    distance.cosine(toy_story_vec, shrek_vec),\\n\u0022, \u0022    distance.cosine(toy_story_vec, exorcist_vec),\\n\u0022, \u0022    sep=\u0027\\\\n\u0027\\n\u0022, \u0022)\u0022]}, {\u0022cell_type\u0022: \u0022markdown\u0022, \u0022source\u0022: [\u0022\u003e **Aside:** *Why* is cosine distance commonly used when working with embeddings? The short answer, as with so many deep learning techniques, is \\\u0022empirically, it works well\\\u0022. In the exercise coming up, you\u0027ll get to do a little hands-on investigation that digs into this question more deeply.\\n\u0022, \u0022\\n\u0022, \u0022Which movies are most similar to *Toy Story*? Which movies fall right between *Psycho* and *Scream* in the embedding space? We could write a bunch of code to work out questions like this, but it\u0027d be pretty tedious. Fortunately, there\u0027s already a library for exactly this sort of work: **Gensim**.\\n\u0022, \u0022\\n\u0022, \u0022# Exploring embeddings with Gensim\\n\u0022, \u0022\\n\u0022, \u0022I\u0027ll instantiate an instance of [`WordEmbeddingsKeyedVectors`](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.WordEmbeddingsKeyedVectors) with our model\u0027s movie embeddings and the titles of the corresponding movies.\\n\u0022, \u0022\\n\u0022, \u0022\u003e Aside: You may notice that Gensim\u0027s docs and many of its class and method names refer to *word* embeddings. While the library is most frequently used in the text domain, we can use it to explore embeddings of any sort.\u0022], \u0022metadata\u0022: {}}, {\u0022cell_type\u0022: \u0022code\u0022, \u0022execution_count\u0022: null, \u0022metadata\u0022: {}, \u0022outputs\u0022: [], \u0022source\u0022: [\u0022from gensim.models.keyedvectors import WordEmbeddingsKeyedVectors\\n\u0022, \u0022\\n\u0022, \u0022# Limit to movies with at least this many ratings in the dataset\\n\u0022, \u0022threshold = 100\\n\u0022, \u0022mainstream_movies = movies_df[movies_df.n_ratings \u003e= threshold].reset_index(drop=True)\\n\u0022, \u0022\\n\u0022, \u0022movie_embedding_size = w.shape[1]\\n\u0022, \u0022kv = WordEmbeddingsKeyedVectors(movie_embedding_size)\\n\u0022, \u0022kv.add(\\n\u0022, \u0022    mainstream_movies[\u0027key\u0027].values,\\n\u0022, \u0022    w[mainstream_movies.movieId]\\n\u0022, \u0022)\u0022]}, {\u0022cell_type\u0022: \u0022markdown\u0022, \u0022source\u0022: [\u0022Okay, so which movies are most similar to *Toy Story*?\u0022], \u0022metadata\u0022: {}}, {\u0022cell_type\u0022: \u0022code\u0022, \u0022execution_count\u0022: null, \u0022metadata\u0022: {}, \u0022outputs\u0022: [], \u0022source\u0022: [\u0022kv.most_similar(\u0027Toy Story\u0027)\u0022]}, {\u0022cell_type\u0022: \u0022markdown\u0022, \u0022source\u0022: [\u0022Wow, these are pretty great! It makes perfect sense that *Toy Story 2* is the most similar movie to *Toy Story*. And most of the rest are animated kids movies with a similar computer-animated style.\u0022], \u0022metadata\u0022: {}}, {\u0022cell_type\u0022: \u0022markdown\u0022, \u0022source\u0022: [\u0022So it\u0027s learned something about 3-d animated kids flick, but maybe that was just a fluke. Let\u0027s look at the closest neighbours for a few more movies from a variety of genres:\u0022], \u0022metadata\u0022: {}}, {\u0022cell_type\u0022: \u0022code\u0022, \u0022execution_count\u0022: null, \u0022metadata\u0022: {\u0022_kg_hide-input\u0022: true}, \u0022outputs\u0022: [], \u0022source\u0022: [\u0022\\n\u0022, \u0022import textwrap\\n\u0022, \u0022movies = [\u0027Eyes Wide Shut\u0027, \u0027American Pie\u0027, \u0027Iron Man 3\u0027, \u0027West Side Story\u0027,\\n\u0022, \u0022          \u0027Battleship Potemkin\u0027, \u0027Clueless\u0027\\n\u0022, \u0022]\\n\u0022, \u0022\\n\u0022, \u0022def plot_most_similar(movie, ax, topn=5):\\n\u0022, \u0022    sim = kv.most_similar(movie, topn=topn)[::-1]\\n\u0022, \u0022    y = np.arange(len(sim))\\n\u0022, \u0022    w = [t[1] for t in sim]\\n\u0022, \u0022    ax.barh(y, w)\\n\u0022, \u0022    left = min(.6, min(w))\\n\u0022, \u0022    ax.set_xlim(right=1.0, left=left)\\n\u0022, \u0022    # Split long titles over multiple lines\\n\u0022, \u0022    labels = [textwrap.fill(t[0] , width=24)\\n\u0022, \u0022              for t in sim]\\n\u0022, \u0022    ax.set_yticks(y)\\n\u0022, \u0022    ax.set_yticklabels(labels)\\n\u0022, \u0022    ax.set_title(movie)    \\n\u0022, \u0022\\n\u0022, \u0022fig, axes = plt.subplots(3, 2, figsize=(15, 9))\\n\u0022, \u0022\\n\u0022, \u0022for movie, ax in zip(movies, axes.flatten()):\\n\u0022, \u0022    plot_most_similar(movie, ax)\\n\u0022, \u0022    \\n\u0022, \u0022fig.tight_layout()\u0022]}, {\u0022cell_type\u0022: \u0022markdown\u0022, \u0022source\u0022: [\u0022Artsy erotic dramas, raunchy sophomoric comedies, old-school musicals, superhero movies... our embeddings manage to nail a wide variety of cinematic niches!\u0022], \u0022metadata\u0022: {}}, {\u0022cell_type\u0022: \u0022markdown\u0022, \u0022source\u0022: [\u0022# Semantic vector math\\n\u0022, \u0022\\n\u0022, \u0022The [`most_similar`](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.most_similar) method optionally takes a second argument, `negative`. If we call `kv.most_similar(a, b)`, then instead of finding the vector closest to `a`, it will find the closest vector to `a - b`.\\n\u0022, \u0022\\n\u0022, \u0022Why would you want to do that? It turns out that doing addition and subtraction of embedding vectors often gives surprisingly meaningful results. For example, how would you fill in the following equation?\\n\u0022, \u0022\\n\u0022, \u0022    Scream = Psycho + ________\\n\u0022, \u0022\\n\u0022, \u0022*Scream* and *Psycho* are similar in that they\u0027re violent, scary movies somewhere on the border between Horror and Thriller. The biggest difference is that *Scream* has elements of comedy. So I\u0027d say *Scream* is what you\u0027d get if you combined *Psycho* with a comedy.\\n\u0022, \u0022\\n\u0022, \u0022But we can actually ask Gensim to fill in the blank for us via vector math (after some rearranging):\\n\u0022, \u0022\\n\u0022, \u0022    ________ = Scream - Psycho\u0022], \u0022metadata\u0022: {}}, {\u0022cell_type\u0022: \u0022code\u0022, \u0022execution_count\u0022: null, \u0022metadata\u0022: {}, \u0022outputs\u0022: [], \u0022source\u0022: [\u0022kv.most_similar(\\n\u0022, \u0022    positive = [\u0027Scream\u0027],\\n\u0022, \u0022    negative = [\u0027Psycho (1960)\u0027]\\n\u0022, \u0022)\u0022]}, {\u0022cell_type\u0022: \u0022markdown\u0022, \u0022source\u0022: [\u0022If you are familiar with these movies, you\u0027ll see that the missing ingredient that takes us from *Psycho* to *Scream* is comedy (and also late-90\u0027s-teen-movie-ness).\u0022], \u0022metadata\u0022: {}}, {\u0022cell_type\u0022: \u0022markdown\u0022, \u0022source\u0022: [\u0022## Analogy solving\\n\u0022, \u0022\\n\u0022, \u0022The SAT test which is used to get into American colleges and universities poses analogy questions like:\\n\u0022, \u0022\\n\u0022, \u0022    shower : deluge :: _____ : stare\\n\u0022, \u0022    \\n\u0022, \u0022(Read \\\u0022shower is to deluge as ___ is to stare\\\u0022)\\n\u0022, \u0022\\n\u0022, \u0022To solve this, we find the relationship between deluge and shower, and apply it to stare. A shower is a milder form of a deluge. What\u0027s a milder form of stare? A good answer here would be \\\u0022glance\\\u0022, or \\\u0022look\\\u0022. \\n\u0022, \u0022\\n\u0022, \u0022It\u0027s kind of astounding that this works, but people have found that these can often be effectively solved by simple vector math on word embeddings. Can we solve movie analogies with our embeddings? Let\u0027s try. What about:\\n\u0022, \u0022\\n\u0022, \u0022    Brave : Cars 2 :: Pocahontas : _____\\n\u0022, \u0022    \\n\u0022, \u0022The answer is not clear. One interpretation would be that *Brave* is like *Cars 2*, except that the latter is aimed primarily at boys, and the former might be more appealing to girls, given its female protagonist. So maybe the answer should be, like *Pocahontas*, a mid-90\u0027s conventional animation kids movie, but more of a \u0027boy movie\u0027. *Hercules*? *The Lion King*? \\n\u0022, \u0022\\n\u0022, \u0022Let\u0027s ask our embeddings what they think.\\n\u0022, \u0022\\n\u0022, \u0022In terms of vector math, we can frame this as...\\n\u0022, \u0022\\n\u0022, \u0022    Cars 2 = Brave + X\\n\u0022, \u0022    _____  = Pocahontas + X\\n\u0022, \u0022    \\n\u0022, \u0022Rearranging, we get:\\n\u0022, \u0022\\n\u0022, \u0022    ____ = Pocahontas + (Cars 2 - Brave)\\n\u0022, \u0022\\n\u0022, \u0022We can solve this by passing in two movies (*Pocahontas* and *Cars 2*) for the positive argument to `most_similar`, with *Brave* as the negative argument:\u0022], \u0022metadata\u0022: {}}, {\u0022cell_type\u0022: \u0022code\u0022, \u0022execution_count\u0022: null, \u0022metadata\u0022: {}, \u0022outputs\u0022: [], \u0022source\u0022: [\u0022kv.most_similar(\\n\u0022, \u0022    [\u0027Pocahontas\u0027, \u0027Cars 2\u0027],\\n\u0022, \u0022    negative = [\u0027Brave\u0027]\\n\u0022, \u0022)\u0022]}, {\u0022cell_type\u0022: \u0022markdown\u0022, \u0022source\u0022: [\u0022This weakly fits our prediction: the 4 closest movies are indeed kids animated movies from the 90s. After that, the results are a bit more perplexing.\\n\u0022, \u0022\\n\u0022, \u0022Is our model wrong, or were we? Another difference we failed to account for between *Cars 2* and *Brave* is that the former is a sequel, and the latter is not. 7/10 of our results are also sequels. This tells us something interesting about our learned embeddings (and, ultimately, about the problem of predicting movie preferences). \\\u0022Sequelness\\\u0022 is an important property to our model - which suggests that some of the variance in our data is accounted for the fact that some people tend to like sequels more than others.\u0022], \u0022metadata\u0022: {}}, {\u0022cell_type\u0022: \u0022markdown\u0022, \u0022source\u0022: [\u0022# Your turn!\\n\u0022, \u0022\\n\u0022, \u0022Head over to [the Exercises notebook](https://www.kaggle.com/kernels/fork/1598893) to get some hands-on practice working with exploring embeddings with gensim.\\n\u0022, \u0022### P.S...\\n\u0022, \u0022\\n\u0022, \u0022This course is still in beta, so I\u0027d love to get your feedback. If you have a moment to [fill out a super-short survey about this lesson](https://form.jotform.com/82826473884269), I\u0027d greatly appreciate it. You can also leave public feedback in the comments below, or on the [Learn Forum](https://www.kaggle.com/learn-forum).\\n\u0022], \u0022metadata\u0022: {}}], \u0022metadata\u0022: {\u0022language_info\u0022: {\u0022file_extension\u0022: \u0022.py\u0022, \u0022mimetype\u0022: \u0022text/x-python\u0022, \u0022pygments_lexer\u0022: \u0022ipython3\u0022, \u0022version\u0022: \u00223.6.5\u0022, \u0022nbconvert_exporter\u0022: \u0022python\u0022, \u0022codemirror_mode\u0022: {\u0022name\u0022: \u0022ipython\u0022, \u0022version\u0022: 3}, \u0022name\u0022: \u0022python\u0022}, \u0022kernelspec\u0022: {\u0022name\u0022: \u0022python3\u0022, \u0022language\u0022: \u0022python\u0022, \u0022display_name\u0022: \u0022Python 3\u0022}, \u0022learntools_metadata\u0022: {\u0022type\u0022: \u0022tutorial\u0022, \u0022lesson_index\u0022: 2}}, \u0022nbformat\u0022: 4, \u0022nbformat_minor\u0022: 2}","dateCreated":"2018-10-11T00:04:59.4218632Z"},"kernelRun":{"id":6375458,"kernelId":1598892,"status":"complete","type":"batch","sourceType":"notebook","language":"python","title":"Exploring Embeddings With Gensim","dateCreated":"2018-10-11T00:04:59.453Z","dateEvaluated":"2018-10-11T00:04:59.987Z","workerContainerPort":null,"workerUptimeSeconds":151678,"workerIPAddress":"172.16.21.234  ","scriptLanguageId":9,"scriptLanguageName":"IPython Notebook HTML","renderedOutputUrl":"https://www.kaggleusercontent.com/kf/6375458/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..EHct1GamEDPbLuV7X12Sxw.kZRyOSNw44OFIKIzdn7hLF6JDASB-qqCLdyhFMKBriBIbvwHHPA3l17-gILnddMlC1PQMVXbZxynsHsua5KR9_06FDAKhqIIu23AuW875RtagQAamfYdsAuRh25FWiQyAh3MW1l9oRtOlCaF5iDsGNOujiOQNGjof6hXRYxXxOk.9l4t2X4NBmN7OJJW5zSAww/__results__.html","commit":{"id":77057265,"settings":{"dockerImageVersionId":null,"dataSources":[{"sourceType":"KernelVersion","sourceId":6373076,"databundleVersionId":null,"mountSlug":null},{"sourceType":"KernelVersion","sourceId":6373082,"databundleVersionId":null,"mountSlug":null}],"sourceType":"notebook","language":"python","isGpuEnabled":false,"isInternetEnabled":false},"source":"{\u0022cells\u0022: [{\u0022cell_type\u0022: \u0022markdown\u0022, \u0022source\u0022: [\u0022Earlier we trained a model to predict the ratings users would give to movies using a network with embeddings learned for each movie and user. Embeddings are powerful! But how do they actually work? \\n\u0022, \u0022\\n\u0022, \u0022Previously, I claimed that embeddings capture the \u0027meaning\u0027 of the objects they represent, and discover useful latent structure. Let\u0027s put that to the test!\\n\u0022, \u0022\\n\u0022, \u0022# Looking up embeddings\\n\u0022, \u0022\\n\u0022, \u0022Let\u0027s load a model we trained earlier so we can investigate the embedding weights that it learned.\u0022], \u0022metadata\u0022: {}}, {\u0022cell_type\u0022: \u0022code\u0022, \u0022execution_count\u0022: null, \u0022metadata\u0022: {}, \u0022outputs\u0022: [], \u0022source\u0022: [\u0022import os\\n\u0022, \u0022\\n\u0022, \u0022import numpy as np\\n\u0022, \u0022import pandas as pd\\n\u0022, \u0022from matplotlib import pyplot as plt\\n\u0022, \u0022import tensorflow as tf\\n\u0022, \u0022from tensorflow import keras\\n\u0022, \u0022\\n\u0022, \u0022input_dir = \u0027../input/movielens-preprocessing\u0027\\n\u0022, \u0022model_dir = \u0027../input/movielens-spiffy-model\u0027\\n\u0022, \u0022model_path = os.path.join(model_dir, \u0027movie_svd_model_32.h5\u0027)\\n\u0022, \u0022model = keras.models.load_model(model_path)\u0022]}, {\u0022cell_type\u0022: \u0022markdown\u0022, \u0022source\u0022: [\u0022The embedding weights are part of the model\u0027s internals, so we\u0027ll have to do a bit of digging around to access them. We\u0027ll grab the layer responsible for embedding movies, and use the `get_weights()` method to get its learned weights.\u0022], \u0022metadata\u0022: {}}, {\u0022cell_type\u0022: \u0022code\u0022, \u0022execution_count\u0022: null, \u0022metadata\u0022: {}, \u0022outputs\u0022: [], \u0022source\u0022: [\u0022emb_layer = model.get_layer(\u0027movie_embedding\u0027)\\n\u0022, \u0022(w,) = emb_layer.get_weights()\\n\u0022, \u0022w.shape\u0022]}, {\u0022cell_type\u0022: \u0022markdown\u0022, \u0022source\u0022: [\u0022Our weight matrix has 26,744 rows for that many movies. Each row is 32 numbers - the size of our movie embeddings.\\n\u0022, \u0022\\n\u0022, \u0022Let\u0027s look at an example movie vector:\u0022], \u0022metadata\u0022: {}}, {\u0022cell_type\u0022: \u0022code\u0022, \u0022execution_count\u0022: null, \u0022metadata\u0022: {}, \u0022outputs\u0022: [], \u0022source\u0022: [\u0022w[0]\u0022]}, {\u0022cell_type\u0022: \u0022markdown\u0022, \u0022source\u0022: [\u0022What movie is this the embedding of? Let\u0027s load up our dataframe of movie metadata.\u0022], \u0022metadata\u0022: {}}, {\u0022cell_type\u0022: \u0022code\u0022, \u0022execution_count\u0022: null, \u0022metadata\u0022: {}, \u0022outputs\u0022: [], \u0022source\u0022: [\u0022movies_path = os.path.join(input_dir, \u0027movie.csv\u0027)\\n\u0022, \u0022movies_df = pd.read_csv(movies_path, index_col=0)\\n\u0022, \u0022movies_df.head()\u0022]}, {\u0022cell_type\u0022: \u0022markdown\u0022, \u0022source\u0022: [\u0022Of course, it\u0027s *Toy Story*! I should have recognized that vector anywhere.\\n\u0022, \u0022\\n\u0022, \u0022Okay, I\u0027m being facetious. It\u0027s hard to make anything of these vectors at this point. We never directed the model about how to use any particular embedding dimension. We left it alone to learn whatever representation it found useful.\\n\u0022, \u0022\\n\u0022, \u0022So how do we check whether these representations are sane and coherent?\\n\u0022, \u0022\\n\u0022, \u0022## Vector similarity\\n\u0022, \u0022\\n\u0022, \u0022A simple way to test this is to look at how close or distant pairs of movies are in the embedding space. Embeddings can be thought of as a smart distance metric. If our embedding matrix is any good, it should map similar movies (like *Toy Story* and *Shrek*) to similar vectors.\u0022], \u0022metadata\u0022: {}}, {\u0022cell_type\u0022: \u0022code\u0022, \u0022execution_count\u0022: null, \u0022metadata\u0022: {}, \u0022outputs\u0022: [], \u0022source\u0022: [\u0022i_toy_story = 0\\n\u0022, \u0022i_shrek = movies_df.loc[\\n\u0022, \u0022    movies_df.title == \u0027Shrek\u0027,\\n\u0022, \u0022    \u0027movieId\u0027\\n\u0022, \u0022].iloc[0]\\n\u0022, \u0022\\n\u0022, \u0022toy_story_vec = w[i_toy_story]\\n\u0022, \u0022shrek_vec = w[i_shrek]\\n\u0022, \u0022\\n\u0022, \u0022print(\\n\u0022, \u0022    toy_story_vec,\\n\u0022, \u0022    shrek_vec,\\n\u0022, \u0022    sep=\u0027\\\\n\u0027,\\n\u0022, \u0022)\u0022]}, {\u0022cell_type\u0022: \u0022markdown\u0022, \u0022source\u0022: [\u0022Comparing dimension-by-dimension, these look vaguely similar. If we wanted to assign a single number to their similarity, we could calculate the euclidean distance between these two vectors. (This is our conventional \u0027as the crow flies\u0027 notion of distance between two points. Easy to grok in 1, 2, or 3 dimensions. Mathematically, we can also extend it to 32 dimensions, though good luck visualizing it.)\u0022], \u0022metadata\u0022: {}}, {\u0022cell_type\u0022: \u0022code\u0022, \u0022execution_count\u0022: null, \u0022metadata\u0022: {}, \u0022outputs\u0022: [], \u0022source\u0022: [\u0022from scipy.spatial import distance\\n\u0022, \u0022\\n\u0022, \u0022distance.euclidean(toy_story_vec, shrek_vec)\u0022]}, {\u0022cell_type\u0022: \u0022markdown\u0022, \u0022source\u0022: [\u0022How does this compare to a pair of movies that we would think of as very different?\u0022], \u0022metadata\u0022: {}}, {\u0022cell_type\u0022: \u0022code\u0022, \u0022execution_count\u0022: null, \u0022metadata\u0022: {}, \u0022outputs\u0022: [], \u0022source\u0022: [\u0022i_exorcist = movies_df.loc[\\n\u0022, \u0022    movies_df.title == \u0027The Exorcist\u0027,\\n\u0022, \u0022    \u0027movieId\u0027\\n\u0022, \u0022].iloc[0]\\n\u0022, \u0022\\n\u0022, \u0022exorcist_vec = w[i_exorcist]\\n\u0022, \u0022\\n\u0022, \u0022distance.euclidean(toy_story_vec, exorcist_vec)\u0022]}, {\u0022cell_type\u0022: \u0022markdown\u0022, \u0022source\u0022: [\u0022As expected, much further apart.\\n\u0022, \u0022\\n\u0022, \u0022## Cosine Distance\\n\u0022, \u0022\\n\u0022, \u0022If you check out [the docs for the `scipy.spatial` module](https://docs.scipy.org/doc/scipy-0.14.0/reference/spatial.distance.html), you\u0027ll see there are actually a *lot* of different measures of distance that people use for different tasks.\\n\u0022, \u0022\\n\u0022, \u0022When judging the similarity of embeddings, it\u0027s more common to use [cosine similarity](https://en.wikipedia.org/wiki/Cosine_similarity).\\n\u0022, \u0022\\n\u0022, \u0022In brief, the cosine similarity of two vectors ranges from -1 to 1, and is a function of the *angle* between the vectors. If two vectors point in the same direction, their cosine similarity is 1. If they point in opposite directions, it\u0027s -1. If they\u0027re orthogonal (i.e. at right angles), their cosine similarity is 0.\\n\u0022, \u0022\\n\u0022, \u0022Cosine distance is just defined as 1 minus the cosine similarity (and therefore ranges from 0 to 2).\\n\u0022, \u0022\\n\u0022, \u0022Let\u0027s calculate a couple cosine distances between movie vectors:\u0022], \u0022metadata\u0022: {}}, {\u0022cell_type\u0022: \u0022code\u0022, \u0022execution_count\u0022: null, \u0022metadata\u0022: {}, \u0022outputs\u0022: [], \u0022source\u0022: [\u0022print(\\n\u0022, \u0022    distance.cosine(toy_story_vec, shrek_vec),\\n\u0022, \u0022    distance.cosine(toy_story_vec, exorcist_vec),\\n\u0022, \u0022    sep=\u0027\\\\n\u0027\\n\u0022, \u0022)\u0022]}, {\u0022cell_type\u0022: \u0022markdown\u0022, \u0022source\u0022: [\u0022\u003e **Aside:** *Why* is cosine distance commonly used when working with embeddings? The short answer, as with so many deep learning techniques, is \\\u0022empirically, it works well\\\u0022. In the exercise coming up, you\u0027ll get to do a little hands-on investigation that digs into this question more deeply.\\n\u0022, \u0022\\n\u0022, \u0022Which movies are most similar to *Toy Story*? Which movies fall right between *Psycho* and *Scream* in the embedding space? We could write a bunch of code to work out questions like this, but it\u0027d be pretty tedious. Fortunately, there\u0027s already a library for exactly this sort of work: **Gensim**.\\n\u0022, \u0022\\n\u0022, \u0022# Exploring embeddings with Gensim\\n\u0022, \u0022\\n\u0022, \u0022I\u0027ll instantiate an instance of [`WordEmbeddingsKeyedVectors`](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.WordEmbeddingsKeyedVectors) with our model\u0027s movie embeddings and the titles of the corresponding movies.\\n\u0022, \u0022\\n\u0022, \u0022\u003e Aside: You may notice that Gensim\u0027s docs and many of its class and method names refer to *word* embeddings. While the library is most frequently used in the text domain, we can use it to explore embeddings of any sort.\u0022], \u0022metadata\u0022: {}}, {\u0022cell_type\u0022: \u0022code\u0022, \u0022execution_count\u0022: null, \u0022metadata\u0022: {}, \u0022outputs\u0022: [], \u0022source\u0022: [\u0022from gensim.models.keyedvectors import WordEmbeddingsKeyedVectors\\n\u0022, \u0022\\n\u0022, \u0022# Limit to movies with at least this many ratings in the dataset\\n\u0022, \u0022threshold = 100\\n\u0022, \u0022mainstream_movies = movies_df[movies_df.n_ratings \u003e= threshold].reset_index(drop=True)\\n\u0022, \u0022\\n\u0022, \u0022movie_embedding_size = w.shape[1]\\n\u0022, \u0022kv = WordEmbeddingsKeyedVectors(movie_embedding_size)\\n\u0022, \u0022kv.add(\\n\u0022, \u0022    mainstream_movies[\u0027key\u0027].values,\\n\u0022, \u0022    w[mainstream_movies.movieId]\\n\u0022, \u0022)\u0022]}, {\u0022cell_type\u0022: \u0022markdown\u0022, \u0022source\u0022: [\u0022Okay, so which movies are most similar to *Toy Story*?\u0022], \u0022metadata\u0022: {}}, {\u0022cell_type\u0022: \u0022code\u0022, \u0022execution_count\u0022: null, \u0022metadata\u0022: {}, \u0022outputs\u0022: [], \u0022source\u0022: [\u0022kv.most_similar(\u0027Toy Story\u0027)\u0022]}, {\u0022cell_type\u0022: \u0022markdown\u0022, \u0022source\u0022: [\u0022Wow, these are pretty great! It makes perfect sense that *Toy Story 2* is the most similar movie to *Toy Story*. And most of the rest are animated kids movies with a similar computer-animated style.\u0022], \u0022metadata\u0022: {}}, {\u0022cell_type\u0022: \u0022markdown\u0022, \u0022source\u0022: [\u0022So it\u0027s learned something about 3-d animated kids flick, but maybe that was just a fluke. Let\u0027s look at the closest neighbours for a few more movies from a variety of genres:\u0022], \u0022metadata\u0022: {}}, {\u0022cell_type\u0022: \u0022code\u0022, \u0022execution_count\u0022: null, \u0022metadata\u0022: {\u0022_kg_hide-input\u0022: true}, \u0022outputs\u0022: [], \u0022source\u0022: [\u0022\\n\u0022, \u0022import textwrap\\n\u0022, \u0022movies = [\u0027Eyes Wide Shut\u0027, \u0027American Pie\u0027, \u0027Iron Man 3\u0027, \u0027West Side Story\u0027,\\n\u0022, \u0022          \u0027Battleship Potemkin\u0027, \u0027Clueless\u0027\\n\u0022, \u0022]\\n\u0022, \u0022\\n\u0022, \u0022def plot_most_similar(movie, ax, topn=5):\\n\u0022, \u0022    sim = kv.most_similar(movie, topn=topn)[::-1]\\n\u0022, \u0022    y = np.arange(len(sim))\\n\u0022, \u0022    w = [t[1] for t in sim]\\n\u0022, \u0022    ax.barh(y, w)\\n\u0022, \u0022    left = min(.6, min(w))\\n\u0022, \u0022    ax.set_xlim(right=1.0, left=left)\\n\u0022, \u0022    # Split long titles over multiple lines\\n\u0022, \u0022    labels = [textwrap.fill(t[0] , width=24)\\n\u0022, \u0022              for t in sim]\\n\u0022, \u0022    ax.set_yticks(y)\\n\u0022, \u0022    ax.set_yticklabels(labels)\\n\u0022, \u0022    ax.set_title(movie)    \\n\u0022, \u0022\\n\u0022, \u0022fig, axes = plt.subplots(3, 2, figsize=(15, 9))\\n\u0022, \u0022\\n\u0022, \u0022for movie, ax in zip(movies, axes.flatten()):\\n\u0022, \u0022    plot_most_similar(movie, ax)\\n\u0022, \u0022    \\n\u0022, \u0022fig.tight_layout()\u0022]}, {\u0022cell_type\u0022: \u0022markdown\u0022, \u0022source\u0022: [\u0022Artsy erotic dramas, raunchy sophomoric comedies, old-school musicals, superhero movies... our embeddings manage to nail a wide variety of cinematic niches!\u0022], \u0022metadata\u0022: {}}, {\u0022cell_type\u0022: \u0022markdown\u0022, \u0022source\u0022: [\u0022# Semantic vector math\\n\u0022, \u0022\\n\u0022, \u0022The [`most_similar`](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.most_similar) method optionally takes a second argument, `negative`. If we call `kv.most_similar(a, b)`, then instead of finding the vector closest to `a`, it will find the closest vector to `a - b`.\\n\u0022, \u0022\\n\u0022, \u0022Why would you want to do that? It turns out that doing addition and subtraction of embedding vectors often gives surprisingly meaningful results. For example, how would you fill in the following equation?\\n\u0022, \u0022\\n\u0022, \u0022    Scream = Psycho + ________\\n\u0022, \u0022\\n\u0022, \u0022*Scream* and *Psycho* are similar in that they\u0027re violent, scary movies somewhere on the border between Horror and Thriller. The biggest difference is that *Scream* has elements of comedy. So I\u0027d say *Scream* is what you\u0027d get if you combined *Psycho* with a comedy.\\n\u0022, \u0022\\n\u0022, \u0022But we can actually ask Gensim to fill in the blank for us via vector math (after some rearranging):\\n\u0022, \u0022\\n\u0022, \u0022    ________ = Scream - Psycho\u0022], \u0022metadata\u0022: {}}, {\u0022cell_type\u0022: \u0022code\u0022, \u0022execution_count\u0022: null, \u0022metadata\u0022: {}, \u0022outputs\u0022: [], \u0022source\u0022: [\u0022kv.most_similar(\\n\u0022, \u0022    positive = [\u0027Scream\u0027],\\n\u0022, \u0022    negative = [\u0027Psycho (1960)\u0027]\\n\u0022, \u0022)\u0022]}, {\u0022cell_type\u0022: \u0022markdown\u0022, \u0022source\u0022: [\u0022If you are familiar with these movies, you\u0027ll see that the missing ingredient that takes us from *Psycho* to *Scream* is comedy (and also late-90\u0027s-teen-movie-ness).\u0022], \u0022metadata\u0022: {}}, {\u0022cell_type\u0022: \u0022markdown\u0022, \u0022source\u0022: [\u0022## Analogy solving\\n\u0022, \u0022\\n\u0022, \u0022The SAT test which is used to get into American colleges and universities poses analogy questions like:\\n\u0022, \u0022\\n\u0022, \u0022    shower : deluge :: _____ : stare\\n\u0022, \u0022    \\n\u0022, \u0022(Read \\\u0022shower is to deluge as ___ is to stare\\\u0022)\\n\u0022, \u0022\\n\u0022, \u0022To solve this, we find the relationship between deluge and shower, and apply it to stare. A shower is a milder form of a deluge. What\u0027s a milder form of stare? A good answer here would be \\\u0022glance\\\u0022, or \\\u0022look\\\u0022. \\n\u0022, \u0022\\n\u0022, \u0022It\u0027s kind of astounding that this works, but people have found that these can often be effectively solved by simple vector math on word embeddings. Can we solve movie analogies with our embeddings? Let\u0027s try. What about:\\n\u0022, \u0022\\n\u0022, \u0022    Brave : Cars 2 :: Pocahontas : _____\\n\u0022, \u0022    \\n\u0022, \u0022The answer is not clear. One interpretation would be that *Brave* is like *Cars 2*, except that the latter is aimed primarily at boys, and the former might be more appealing to girls, given its female protagonist. So maybe the answer should be, like *Pocahontas*, a mid-90\u0027s conventional animation kids movie, but more of a \u0027boy movie\u0027. *Hercules*? *The Lion King*? \\n\u0022, \u0022\\n\u0022, \u0022Let\u0027s ask our embeddings what they think.\\n\u0022, \u0022\\n\u0022, \u0022In terms of vector math, we can frame this as...\\n\u0022, \u0022\\n\u0022, \u0022    Cars 2 = Brave + X\\n\u0022, \u0022    _____  = Pocahontas + X\\n\u0022, \u0022    \\n\u0022, \u0022Rearranging, we get:\\n\u0022, \u0022\\n\u0022, \u0022    ____ = Pocahontas + (Cars 2 - Brave)\\n\u0022, \u0022\\n\u0022, \u0022We can solve this by passing in two movies (*Pocahontas* and *Cars 2*) for the positive argument to `most_similar`, with *Brave* as the negative argument:\u0022], \u0022metadata\u0022: {}}, {\u0022cell_type\u0022: \u0022code\u0022, \u0022execution_count\u0022: null, \u0022metadata\u0022: {}, \u0022outputs\u0022: [], \u0022source\u0022: [\u0022kv.most_similar(\\n\u0022, \u0022    [\u0027Pocahontas\u0027, \u0027Cars 2\u0027],\\n\u0022, \u0022    negative = [\u0027Brave\u0027]\\n\u0022, \u0022)\u0022]}, {\u0022cell_type\u0022: \u0022markdown\u0022, \u0022source\u0022: [\u0022This weakly fits our prediction: the 4 closest movies are indeed kids animated movies from the 90s. After that, the results are a bit more perplexing.\\n\u0022, \u0022\\n\u0022, \u0022Is our model wrong, or were we? Another difference we failed to account for between *Cars 2* and *Brave* is that the former is a sequel, and the latter is not. 7/10 of our results are also sequels. This tells us something interesting about our learned embeddings (and, ultimately, about the problem of predicting movie preferences). \\\u0022Sequelness\\\u0022 is an important property to our model - which suggests that some of the variance in our data is accounted for the fact that some people tend to like sequels more than others.\u0022], \u0022metadata\u0022: {}}, {\u0022cell_type\u0022: \u0022markdown\u0022, \u0022source\u0022: [\u0022# Your turn!\\n\u0022, \u0022\\n\u0022, \u0022Head over to [the Exercises notebook](https://www.kaggle.com/kernels/fork/1598893) to get some hands-on practice working with exploring embeddings with gensim.\\n\u0022, \u0022### P.S...\\n\u0022, \u0022\\n\u0022, \u0022This course is still in beta, so I\u0027d love to get your feedback. If you have a moment to [fill out a super-short survey about this lesson](https://form.jotform.com/82826473884269), I\u0027d greatly appreciate it. You can also leave public feedback in the comments below, or on the [Learn Forum](https://www.kaggle.com/learn-forum).\\n\u0022], \u0022metadata\u0022: {}}], \u0022metadata\u0022: {\u0022language_info\u0022: {\u0022file_extension\u0022: \u0022.py\u0022, \u0022mimetype\u0022: \u0022text/x-python\u0022, \u0022pygments_lexer\u0022: \u0022ipython3\u0022, \u0022version\u0022: \u00223.6.5\u0022, \u0022nbconvert_exporter\u0022: \u0022python\u0022, \u0022codemirror_mode\u0022: {\u0022name\u0022: \u0022ipython\u0022, \u0022version\u0022: 3}, \u0022name\u0022: \u0022python\u0022}, \u0022kernelspec\u0022: {\u0022name\u0022: \u0022python3\u0022, \u0022language\u0022: \u0022python\u0022, \u0022display_name\u0022: \u0022Python 3\u0022}, \u0022learntools_metadata\u0022: {\u0022type\u0022: \u0022tutorial\u0022, \u0022lesson_index\u0022: 2}}, \u0022nbformat\u0022: 4, \u0022nbformat_minor\u0022: 2}","dateCreated":"2018-10-11T00:04:59.4218632Z"},"resources":null,"isolatorResults":"\u003cresults\u003e\u003cdisk_kb_free\u003e4821992\u003c/disk_kb_free\u003e\u003cdocker_image_digest\u003e9784f028e349eb16c0db263ac6d6aa9f75b79e4429c20da5e73879a88e219e39\u003c/docker_image_digest\u003e\u003cdocker_image_id\u003esha256:92e9bd37d14ad1eb5a164f65de9830da245a7dc7e92d42ccced2d5871e31471c\u003c/docker_image_id\u003e\u003cdocker_image_name\u003egcr.io/kaggle-images/python\u003c/docker_image_name\u003e\u003cexit_code\u003e0\u003c/exit_code\u003e\u003cfailure_message /\u003e\u003cinvalid_path_errors\u003eFalse\u003c/invalid_path_errors\u003e\u003cout_of_memory\u003eFalse\u003c/out_of_memory\u003e\u003crun_time_seconds\u003e13.2067083140137\u003c/run_time_seconds\u003e\u003csucceeded\u003eTrue\u003c/succeeded\u003e\u003ctimeout_exceeded\u003eFalse\u003c/timeout_exceeded\u003e\u003cused_all_space\u003eFalse\u003c/used_all_space\u003e\u003cwas_killed\u003eFalse\u003c/was_killed\u003e\u003c/results\u003e","runInfo":{"dockerfileUrl":"https://github.com/Kaggle/docker-python/blob/master/Dockerfile","dockerHubUrl":"https://registry.hub.docker.com/u/kaggle/python/","dockerImageDigest":"9784f028e349eb16c0db263ac6d6aa9f75b79e4429c20da5e73879a88e219e39","dockerImageId":"sha256:92e9bd37d14ad1eb5a164f65de9830da245a7dc7e92d42ccced2d5871e31471c","dockerImageName":"kaggle/python","diskKbFree":4821992,"failureMessage":"","exitCode":0,"queuedSeconds":0,"outputSizeBytes":0,"runTimeSeconds":13.2067083140137,"usedAllSpace":false,"timeoutExceeded":false,"isValidStatus":false,"wasGpuEnabled":false,"wasInternetEnabled":false,"outOfMemory":false,"invalidPathErrors":false,"succeeded":true,"wasKilled":false},"outputFilesTotalSizeBytes":367373,"dockerImageVersionId":11105,"usedCustomDockerImage":false,"dataSources":[{"sourceType":"KernelVersion","sourceId":6373076,"databundleVersionId":null,"mountSlug":"movielens-preprocessing"},{"sourceType":"KernelVersion","sourceId":6373082,"databundleVersionId":null,"mountSlug":"movielens-spiffy-model"}]},"author":{"id":473824,"displayName":"ColinMorris","email":null,"editedEmail":null,"editedEmailCode":null,"userName":"colinmorris","thumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/473824-kg.jpg","profileUrl":"/colinmorris","registerDate":"0001-01-01T00:00:00Z","lastVisitDate":"0001-01-01T00:00:00Z","statusId":0,"performanceTier":3,"userRoles":null,"userLogins":null,"groupIds":null,"duplicateUsers":null,"hasPhoneVerifications":false,"failedNerdchas":0,"hasPendingNerdcha":false,"deleteRequests":null,"userAttributes":null,"isAdmin":false,"isTvc":false,"isKaggleBot":false,"isAdminOrTvc":false,"isAnonymous":false,"canAct":false,"canBeSeen":false,"thumbnailName":null,"activationCode":"00000000-0000-0000-0000-000000000000","isPhoneVerified":false},"baseUrl":"/colinmorris/exploring-embeddings-with-gensim","collaborators":{"owner":{"userId":473824,"groupId":null,"groupMemberCount":null,"profileUrl":"/colinmorris","thumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/473824-kg.jpg","name":"ColinMorris","slug":"colinmorris","userTier":3,"joinDate":null,"type":"owner","isUser":true,"isGroup":false},"collaborators":[{"userId":9028,"groupId":null,"groupMemberCount":null,"profileUrl":"/dansbecker","thumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/9028-fb.jpg","name":"DanB","slug":"dansbecker","userTier":5,"joinDate":"2018-10-11T00:08:59.513Z","type":"writer","isUser":true,"isGroup":false}]},"initialTab":null,"log":"[{\n  \u0022data\u0022: \u0022[NbConvertApp] Converting notebook script.ipynb to html\\n\u0022,\n  \u0022stream_name\u0022: \u0022stderr\u0022,\n  \u0022time\u0022: 4.98324336000951\n},{\n  \u0022data\u0022: \u0022[NbConvertApp] Executing notebook with kernel: python3\\n\u0022,\n  \u0022stream_name\u0022: \u0022stderr\u0022,\n  \u0022time\u0022: 8.411691459012218\n},{\n  \u0022data\u0022: \u00222018-10-11 00:05:09.873622: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:344] Starting optimization for grappler item: tf_graph\\n\u0022,\n  \u0022stream_name\u0022: \u0022stderr\u0022,\n  \u0022time\u0022: 8.919728906999808\n},{\n  \u0022data\u0022: \u00222018-10-11 00:05:09.906158: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:344] Starting optimization for grappler item: tf_graph\\n\u0022,\n  \u0022stream_name\u0022: \u0022stderr\u0022,\n  \u0022time\u0022: 8.953210756997578\n},{\n  \u0022data\u0022: \u00222018-10-11 00:05:09.954588: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:344] Starting optimization for grappler item: tf_graph\\n\u0022,\n  \u0022stream_name\u0022: \u0022stderr\u0022,\n  \u0022time\u0022: 9.000920446997043\n},{\n  \u0022data\u0022: \u0022WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\\n\u0022,\n  \u0022stream_name\u0022: \u0022stderr\u0022,\n  \u0022time\u0022: 9.034424932004185\n},{\n  \u0022data\u0022: \u00222018-10-11 00:05:10.002091: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:344] Starting optimization for grappler item: tf_graph\\n\u0022,\n  \u0022stream_name\u0022: \u0022stderr\u0022,\n  \u0022time\u0022: 9.066386947000865\n},{\n  \u0022data\u0022: \u0022[NbConvertApp] Support files will be in __results___files/\\n[NbConvertApp] Making directory __results___files\\n\u0022,\n  \u0022stream_name\u0022: \u0022stderr\u0022,\n  \u0022time\u0022: 12.428108121996047\n},{\n  \u0022data\u0022: \u0022[NbConvertApp] Writing 314579 bytes to __results__.html\\n\u0022,\n  \u0022stream_name\u0022: \u0022stderr\u0022,\n  \u0022time\u0022: 12.461413662007544\n}]","outputFiles":[],"outputFilesCropped":false,"ouputFilesOwnerInfo":{"databundleVersionId":0,"dataset":null,"competition":null,"kernel":{"kernelId":1598892,"kernelVersionId":6375458,"dataviewToken":"eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..-YfEOJNEc7oTMVRELIi1BQ.aAAW2fsOXJIyKTe9POlJCWavzydMbuGfRwqeOhaGUM9LaiO9WqI0WMXKu9FdwUsQiu9wtaR7a1hwN7va_NIfrTJcJ11yU8WccYBZI3_gp7aQaqJ7PzDL08cAmEKZlClQzrsXEwWL8RlaQ4miymAxt5wmP7PUleqoc6iPpGYAELY9hcwBQba_LrcXEsAwR6wcXqUbEB6DFUGXkyl1wvk_L7bvaLp8llsIzDgtWaeqk3f7ow_beBtW13cka9qxxLcmt2Rmu9VR5sAUQczQYULguywAYNz9T82l6x2PJNjLXOny5nQNgiWcKwMgg4JjS-ux8AjwZg_agOg-9JvM9UaMdVnitod5xd4VM3X47_eqCYmGTcXyre4lCLX97wsuQiV7dmJJQgSkO_cwWYoafQgM2l_gtUaSMgvHyOKh6cIWHcAIVYEqsCFazoPQHRGtCnii6UsRRbu7RNARcQG8cAYy__YZE9RRafr01n9_SNuF-bE.PJeMaaQYvyRS1gPOZYJhbw","scope":"colinmorris/exploring-embeddings-with-gensim"},"previewsDisabled":false},"pageMessages":[],"dataSources":[{"imageUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/473824-kg.jpg","sourceUrl":"/colinmorris/movielens-preprocessing","slug":"movielens-preprocessing","lastUpdated":"2018-10-11T00:04:53.477Z","overview":null,"sourceType":"kernel","sourceVersionType":null,"sourceId":6375455,"sourceVersionNumber":null,"maxVersionNumber":null,"descriptionMimeType":null,"deleted":false,"private":false,"privateButVisible":false,"ownerInfo":{"databundleVersionId":0,"dataset":null,"competition":null,"kernel":{"kernelId":1592008,"kernelVersionId":6375455,"dataviewToken":"eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..hDGzCJmIFqni9KMuEtn0oA.JYiLL9_9sKpnwlOW54d-FnwwfL-yJ6netFPK6tvITgDKJ7UpzBwe0nVcrMTDtIF_KFeCNf2n7ILb4bcf6uePnvnKgczvyRykUuUzzk5u71f0rXXdy_Y4YC3bLs9KM67hsbSMKnrI-AP8z3l4zccoToyl--gN1tUl0Ld3CGcmGlHihHFvxFhikUXTuDDsC3-vBxmWFAHH3WwvJFx9gdCai9E-3zc-qWoQLg5Eoa-duVcgLEbAwukxvSbmrILcN33gJg631evMPKP9qfeY2kTA_8kuV5Y4EGS7xeND5NR7AQqeqKlhbhIHZeU6uWBNScVZ4YR2CTzOJjIV93w-ULIjOv56-zaT0ygESQD782D6Sx1qkTZRHywZJAB-pRphtL123unQIIxNU4m10davfvYuGAmrxnrSLgjTlU-9CYgshE2v1iNjxAa7U61CrvabtzMwYzAjURiqN9oA8Fwd6vNvC8j7ITXs6JqH0fkgl4-PpL6S2Rxe4C8sPK0YRclEOr9FfW4l-jPM2fa89Ko7FUwteo6ztKuUQGTRXSETSlDENklaXQPCfUiozuf-3XB_QY7FiWkY3JLWqmzNoWvSkKyL_A.x2oMf1DRT-ISVXvkSrzkzQ","scope":"868931/movielens-preprocessing"},"previewsDisabled":false},"mountSlug":"movielens-preprocessing","type":"dataSource","collapsed":false,"info":{"metrics":null,"archiveInfo":null,"archiveInfoV2":null,"blobFileInfo":null,"convertCsvInfo":null,"kernelReference":null},"settings":{"csvSettings":null,"bigQuerySettings":null,"bigQueryMirrorSettings":null,"storageSettings":null,"remoteUrlSettings":null,"remoteGithubSettings":null},"render":null,"children":[{"size":77730356,"fullPath":"../input/movielens-preprocessing/mini_rating.csv","previewUrl":"/kernels/preview.json/6375455/EE459E9D-2F16-BB62-A1B5-D73C8F236208/mini_rating.csv","downloadUrl":null,"fileType":"csv","contentLength":0,"contentType":null,"contentMD5":null,"validationErrors":null,"type":"file","collapsed":false,"info":{"metrics":null,"archiveInfo":null,"archiveInfoV2":null,"blobFileInfo":null,"convertCsvInfo":null,"kernelReference":null},"settings":{"csvSettings":null,"bigQuerySettings":null,"bigQueryMirrorSettings":null,"storageSettings":null,"remoteUrlSettings":null,"remoteGithubSettings":null},"render":null,"children":[],"firestorePath":null,"firestoreKey":null,"name":"mini_rating.csv","description":null},{"size":2444966,"fullPath":"../input/movielens-preprocessing/movie.csv","previewUrl":"/kernels/preview.json/6375455/EE459E9D-2F16-BB62-A1B5-D73C8F236208/movie.csv","downloadUrl":null,"fileType":"csv","contentLength":0,"contentType":null,"contentMD5":null,"validationErrors":null,"type":"file","collapsed":false,"info":{"metrics":null,"archiveInfo":null,"archiveInfoV2":null,"blobFileInfo":null,"convertCsvInfo":null,"kernelReference":null},"settings":{"csvSettings":null,"bigQuerySettings":null,"bigQueryMirrorSettings":null,"storageSettings":null,"remoteUrlSettings":null,"remoteGithubSettings":null},"render":null,"children":[],"firestorePath":null,"firestoreKey":null,"name":"movie.csv","description":null},{"size":697372279,"fullPath":"../input/movielens-preprocessing/rating.csv","previewUrl":"/kernels/preview.json/6375455/EE459E9D-2F16-BB62-A1B5-D73C8F236208/rating.csv","downloadUrl":null,"fileType":"csv","contentLength":0,"contentType":null,"contentMD5":null,"validationErrors":null,"type":"file","collapsed":false,"info":{"metrics":null,"archiveInfo":null,"archiveInfoV2":null,"blobFileInfo":null,"convertCsvInfo":null,"kernelReference":null},"settings":{"csvSettings":null,"bigQuerySettings":null,"bigQueryMirrorSettings":null,"storageSettings":null,"remoteUrlSettings":null,"remoteGithubSettings":null},"render":null,"children":[],"firestorePath":null,"firestoreKey":null,"name":"rating.csv","description":null}],"firestorePath":null,"firestoreKey":null,"name":"MovieLens Preprocessing","description":null},{"imageUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/473824-kg.jpg","sourceUrl":"/colinmorris/movielens-spiffy-model","slug":"movielens-spiffy-model","lastUpdated":"2018-11-12T20:50:07.247Z","overview":null,"sourceType":"kernel","sourceVersionType":null,"sourceId":7320109,"sourceVersionNumber":null,"maxVersionNumber":null,"descriptionMimeType":null,"deleted":false,"private":false,"privateButVisible":false,"ownerInfo":{"databundleVersionId":0,"dataset":null,"competition":null,"kernel":{"kernelId":1598079,"kernelVersionId":7320109,"dataviewToken":"eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..Nbii0BMDOK7iyEKUWqL-Zw.JaomnJBiMoDzSKZKiaFzObqPAUuv_wGAGKQ04zBWeMEMdItOR2mZOKxygoNCKl7MQF4qNTi2j57Z7EYKr9c3mHT9zlrA6SZ5NNIgVQXRS85SqYQ4C97U5oFzCzOiXW_ez4M5GdHp9yAc5CZAh8OxoZDVX6o6ErSGRHtZdK6gP9D-v6Z-qAkA2bf-j3DUVfkWnEuMxMzuIChTFy16owXbGvhAs2uCiEQQp6B_Bo4DkOtbJkeVLYAQHX36MsbLMjt38c_Y3bd-Zr52K8YiPc7t3L1LR4tSzc_vfLEJ7fHQHEP5b93cK6ELBqdcPY-eUlhJtdQ7ymqpjGeWirL9mfN5eE5cCEg7BV9LyLXMrMG2OycEnmXeuSER8PGRcTB5e0tLaeVvzevx028bRShEX_Z0wEzfyFhQEsZ3D6lHnG-4SxHksbgG9Bp5RauqQwB0ZFpe2LC44YvUvrUInnrT2Wxj1A.U8GJOu55KmJMHuAQax0dFw","scope":"868931/movielens-spiffy-model"},"previewsDisabled":false},"mountSlug":"movielens-spiffy-model","type":"dataSource","collapsed":false,"info":{"metrics":null,"archiveInfo":null,"archiveInfoV2":null,"blobFileInfo":null,"convertCsvInfo":null,"kernelReference":null},"settings":{"csvSettings":null,"bigQuerySettings":null,"bigQueryMirrorSettings":null,"storageSettings":null,"remoteUrlSettings":null,"remoteGithubSettings":null},"render":null,"children":[{"size":21167528,"fullPath":"../input/movielens-spiffy-model/movie_svd_model_32.h5","previewUrl":"/kernels/preview.json/7320109/75088960-A844-F76C-3FEE-73338CCCA490/movie_svd_model_32.h5","downloadUrl":null,"fileType":"h5","contentLength":0,"contentType":null,"contentMD5":null,"validationErrors":null,"type":"file","collapsed":false,"info":{"metrics":null,"archiveInfo":null,"archiveInfoV2":null,"blobFileInfo":null,"convertCsvInfo":null,"kernelReference":null},"settings":{"csvSettings":null,"bigQuerySettings":null,"bigQueryMirrorSettings":null,"storageSettings":null,"remoteUrlSettings":null,"remoteGithubSettings":null},"render":null,"children":[],"firestorePath":null,"firestoreKey":null,"name":"movie_svd_model_32.h5","description":null}],"firestorePath":null,"firestoreKey":null,"name":"MovieLens Spiffy Model","description":null}],"versions":[{"id":6375458,"kernelVersionId":null,"isForkParent":false,"isNotebook":true,"languageName":"Python","lastRunTime":"2018-10-11T00:04:59.453Z","linesChangedFromPrevious":0,"linesDeletedFromPrevious":1,"linesInsertedFromPrevious":1,"outputFilesTotalSizeBytes":0,"runInfo":{"dockerfileUrl":"https://github.com/Kaggle/docker-python/blob/master/Dockerfile","dockerHubUrl":"https://registry.hub.docker.com/u/kaggle/python/","dockerImageId":"sha256:92e9bd37d14ad1eb5a164f65de9830da245a7dc7e92d42ccced2d5871e31471c","dockerImageName":"gcr.io/kaggle-images/python","exitCode":0,"failureMessage":"","isValidStatus":true,"runTimeSeconds":13.2067083140137,"succeeded":true,"timeoutExceeded":false,"usedAllSpace":false},"status":"complete","title":"Exploring Embeddings With Gensim","url":"/colinmorris/exploring-embeddings-with-gensim?scriptVersionId=6375458","versionNumber":8,"hasVersionNumber":true,"isRedacted":false,"versionAuthor":{"avatarThumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/473824-kg.jpg","displayName":"ColinMorris","userName":"colinmorris","profileUrl":"/colinmorris","tier":"Novice","tierInt":0,"userId":473824}},{"id":6373080,"kernelVersionId":null,"isForkParent":false,"isNotebook":true,"languageName":"Python","lastRunTime":"2018-10-10T21:12:13.25Z","linesChangedFromPrevious":0,"linesDeletedFromPrevious":44,"linesInsertedFromPrevious":7,"outputFilesTotalSizeBytes":0,"runInfo":{"dockerfileUrl":"https://github.com/Kaggle/docker-python/blob/master/Dockerfile","dockerHubUrl":"https://registry.hub.docker.com/u/kaggle/python/","dockerImageId":"sha256:92e9bd37d14ad1eb5a164f65de9830da245a7dc7e92d42ccced2d5871e31471c","dockerImageName":"gcr.io/kaggle-images/python","exitCode":0,"failureMessage":"","isValidStatus":true,"runTimeSeconds":13.4058529579925,"succeeded":true,"timeoutExceeded":false,"usedAllSpace":false},"status":"complete","title":"Exploring Embeddings With Gensim","url":"/colinmorris/exploring-embeddings-with-gensim?scriptVersionId=6373080","versionNumber":7,"hasVersionNumber":true,"isRedacted":false,"versionAuthor":{"avatarThumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/473824-kg.jpg","displayName":"ColinMorris","userName":"colinmorris","profileUrl":"/colinmorris","tier":"Novice","tierInt":0,"userId":473824}},{"id":6370462,"kernelVersionId":null,"isForkParent":false,"isNotebook":true,"languageName":"Python","lastRunTime":"2018-10-10T18:59:06.877Z","linesChangedFromPrevious":0,"linesDeletedFromPrevious":248,"linesInsertedFromPrevious":221,"outputFilesTotalSizeBytes":0,"runInfo":{"dockerfileUrl":"https://github.com/Kaggle/docker-python/blob/master/Dockerfile","dockerHubUrl":"https://registry.hub.docker.com/u/kaggle/python/","dockerImageId":"sha256:92e9bd37d14ad1eb5a164f65de9830da245a7dc7e92d42ccced2d5871e31471c","dockerImageName":"gcr.io/kaggle-images/python","exitCode":0,"failureMessage":"","isValidStatus":true,"runTimeSeconds":12.9013195940061,"succeeded":true,"timeoutExceeded":false,"usedAllSpace":false},"status":"complete","title":"Exploring Embeddings With Gensim","url":"/colinmorris/exploring-embeddings-with-gensim?scriptVersionId=6370462","versionNumber":6,"hasVersionNumber":true,"isRedacted":false,"versionAuthor":{"avatarThumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/473824-kg.jpg","displayName":"ColinMorris","userName":"colinmorris","profileUrl":"/colinmorris","tier":"Novice","tierInt":0,"userId":473824}},{"id":6369979,"kernelVersionId":null,"isForkParent":false,"isNotebook":true,"languageName":"Python","lastRunTime":"2018-10-10T18:37:55.73Z","linesChangedFromPrevious":0,"linesDeletedFromPrevious":0,"linesInsertedFromPrevious":1,"outputFilesTotalSizeBytes":0,"runInfo":{"dockerfileUrl":"https://github.com/Kaggle/docker-python/blob/master/Dockerfile","dockerHubUrl":"https://registry.hub.docker.com/u/kaggle/python/","dockerImageId":"sha256:92e9bd37d14ad1eb5a164f65de9830da245a7dc7e92d42ccced2d5871e31471c","dockerImageName":"gcr.io/kaggle-images/python","exitCode":0,"failureMessage":"","isValidStatus":true,"runTimeSeconds":56.4264566889906,"succeeded":true,"timeoutExceeded":false,"usedAllSpace":false},"status":"complete","title":"Exploring embeddings with gensim","url":"/colinmorris/exploring-embeddings-with-gensim?scriptVersionId=6369979","versionNumber":5,"hasVersionNumber":true,"isRedacted":false,"versionAuthor":{"avatarThumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/473824-kg.jpg","displayName":"ColinMorris","userName":"colinmorris","profileUrl":"/colinmorris","tier":"Novice","tierInt":0,"userId":473824}},{"id":6041117,"kernelVersionId":null,"isForkParent":false,"isNotebook":true,"languageName":"Python","lastRunTime":"2018-09-27T20:12:54.853Z","linesChangedFromPrevious":0,"linesDeletedFromPrevious":5,"linesInsertedFromPrevious":0,"outputFilesTotalSizeBytes":0,"runInfo":{"dockerfileUrl":"https://github.com/Kaggle/docker-python/blob/master/Dockerfile","dockerHubUrl":"https://registry.hub.docker.com/u/kaggle/python/","dockerImageId":"sha256:92e9bd37d14ad1eb5a164f65de9830da245a7dc7e92d42ccced2d5871e31471c","dockerImageName":"gcr.io/kaggle-images/python","exitCode":0,"failureMessage":"","isValidStatus":true,"runTimeSeconds":22.1660163300003,"succeeded":true,"timeoutExceeded":false,"usedAllSpace":false},"status":"complete","title":"3 Exploring embeddings with gensim","url":"/colinmorris/exploring-embeddings-with-gensim?scriptVersionId=6041117","versionNumber":4,"hasVersionNumber":true,"isRedacted":false,"versionAuthor":{"avatarThumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/473824-kg.jpg","displayName":"ColinMorris","userName":"colinmorris","profileUrl":"/colinmorris","tier":"Novice","tierInt":0,"userId":473824}},{"id":5801178,"kernelVersionId":null,"isForkParent":false,"isNotebook":true,"languageName":"Python","lastRunTime":"2018-09-18T19:33:48.4Z","linesChangedFromPrevious":0,"linesDeletedFromPrevious":56,"linesInsertedFromPrevious":66,"outputFilesTotalSizeBytes":0,"runInfo":{"dockerfileUrl":"https://github.com/Kaggle/docker-python/blob/master/Dockerfile","dockerHubUrl":"https://registry.hub.docker.com/u/kaggle/python/","dockerImageId":"sha256:92e9bd37d14ad1eb5a164f65de9830da245a7dc7e92d42ccced2d5871e31471c","dockerImageName":"gcr.io/kaggle-images/python","exitCode":0,"failureMessage":"Too many output files","isValidStatus":true,"runTimeSeconds":55.2302506409978,"succeeded":false,"timeoutExceeded":false,"usedAllSpace":false},"status":"error","title":"3 Exploring embeddings with gensim","url":"/colinmorris/exploring-embeddings-with-gensim?scriptVersionId=5801178","versionNumber":3,"hasVersionNumber":true,"isRedacted":false,"versionAuthor":{"avatarThumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/473824-kg.jpg","displayName":"ColinMorris","userName":"colinmorris","profileUrl":"/colinmorris","tier":"Novice","tierInt":0,"userId":473824}},{"id":5572736,"kernelVersionId":null,"isForkParent":false,"isNotebook":true,"languageName":"Python","lastRunTime":"2018-09-08T00:53:15.67Z","linesChangedFromPrevious":0,"linesDeletedFromPrevious":4,"linesInsertedFromPrevious":2,"outputFilesTotalSizeBytes":0,"runInfo":{"dockerfileUrl":"https://github.com/Kaggle/docker-python/blob/master/Dockerfile","dockerHubUrl":"https://registry.hub.docker.com/u/kaggle/python/","dockerImageId":"sha256:53b26d2bc6d9aa93b7bb9975f1a1887b5237142e673dd30b6a6cc02defbcc4af","dockerImageName":"gcr.io/kaggle-images/python","exitCode":0,"failureMessage":"","isValidStatus":true,"runTimeSeconds":17.9539209089999,"succeeded":true,"timeoutExceeded":false,"usedAllSpace":false},"status":"complete","title":"3 Exploring embeddings with gensim","url":"/colinmorris/exploring-embeddings-with-gensim?scriptVersionId=5572736","versionNumber":2,"hasVersionNumber":true,"isRedacted":false,"versionAuthor":{"avatarThumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/473824-kg.jpg","displayName":"ColinMorris","userName":"colinmorris","profileUrl":"/colinmorris","tier":"Novice","tierInt":0,"userId":473824}},{"id":5572714,"kernelVersionId":null,"isForkParent":false,"isNotebook":true,"languageName":"Python","lastRunTime":"2018-09-08T00:51:26.537Z","linesChangedFromPrevious":0,"linesDeletedFromPrevious":0,"linesInsertedFromPrevious":287,"outputFilesTotalSizeBytes":0,"runInfo":{"dockerfileUrl":"https://github.com/Kaggle/docker-python/blob/master/Dockerfile","dockerHubUrl":"https://registry.hub.docker.com/u/kaggle/python/","dockerImageId":"sha256:53b26d2bc6d9aa93b7bb9975f1a1887b5237142e673dd30b6a6cc02defbcc4af","dockerImageName":"gcr.io/kaggle-images/python","exitCode":0,"failureMessage":"","isValidStatus":true,"runTimeSeconds":10.1933848209956,"succeeded":true,"timeoutExceeded":false,"usedAllSpace":false},"status":"complete","title":"3 Exploring embeddings with gensim","url":"/colinmorris/exploring-embeddings-with-gensim?scriptVersionId=5572714","versionNumber":1,"hasVersionNumber":true,"isRedacted":false,"versionAuthor":{"avatarThumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/473824-kg.jpg","displayName":"ColinMorris","userName":"colinmorris","profileUrl":"/colinmorris","tier":"Novice","tierInt":0,"userId":473824}}],"categories":{"categories":[],"type":"script"},"submitToCompetitionInfo":null,"downloadAllFilesUrl":"/kernels/svzip/6375458","submission":null,"menuLinks":[{"href":"/colinmorris/exploring-embeddings-with-gensim/notebook","text":"Notebook","title":"Notebook","tab":"notebook","count":null,"showZeroCountExplicitly":false,"reportEventCategory":null,"reportEventType":null},{"href":"/colinmorris/exploring-embeddings-with-gensim/code","text":"Code","title":"Code","tab":"code","count":null,"showZeroCountExplicitly":false,"reportEventCategory":null,"reportEventType":null},{"href":"/colinmorris/exploring-embeddings-with-gensim/data","text":"Data","title":"Data","tab":"data","count":2,"showZeroCountExplicitly":false,"reportEventCategory":null,"reportEventType":null},{"href":"/colinmorris/exploring-embeddings-with-gensim/log","text":"Log","title":"Log","tab":"log","count":null,"showZeroCountExplicitly":false,"reportEventCategory":null,"reportEventType":null},{"href":"/colinmorris/exploring-embeddings-with-gensim/comments","text":"Comments","title":"Comments","tab":"comments","count":2,"showZeroCountExplicitly":true,"reportEventCategory":null,"reportEventType":null}],"rightMenuLinks":[],"callToAction":{"href":"/kernels/fork-version/6375458","text":"Fork Notebook","title":"Fork Notebook","tab":null,"count":null,"showZeroCountExplicitly":false,"reportEventCategory":null,"reportEventType":null},"voteButton":{"totalVotes":31,"hasAlreadyVotedUp":false,"hasAlreadyVotedDown":false,"canUpvote":true,"canDownvote":false,"voteUpUrl":"/kernels/vote?id=1598892","voteDownUrl":null,"voters":[{"avatarThumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/110108-kg.JPG","displayName":"Abo Sol","profileUrl":"/abosol","tier":"Novice","tierInt":0,"userId":110108,"userName":"abosol"},{"avatarThumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/131914-kg.jpg","displayName":"Sakares Saengkaew","profileUrl":"/sakares","tier":"Contributor","tierInt":1,"userId":131914,"userName":"sakares"},{"avatarThumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/201481-fb.jpg","displayName":"CXQ","profileUrl":"/caoxiaoqing","tier":"Novice","tierInt":0,"userId":201481,"userName":"caoxiaoqing"},{"avatarThumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/default-thumb.png","displayName":"Donlo Wong","profileUrl":"/cfwongaf","tier":"Contributor","tierInt":1,"userId":248386,"userName":"cfwongaf"},{"avatarThumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/455304-fb.jpg","displayName":"Larry","profileUrl":"/larry0220","tier":"Novice","tierInt":0,"userId":455304,"userName":"larry0220"},{"avatarThumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/default-thumb.png","displayName":"Mileta","profileUrl":"/mileta1976","tier":"Contributor","tierInt":1,"userId":627288,"userName":"mileta1976"},{"avatarThumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/default-thumb.png","displayName":"keetar","profileUrl":"/keetar","tier":"Novice","tierInt":0,"userId":701191,"userName":"keetar"},{"avatarThumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/default-thumb.png","displayName":"little_ordinary","profileUrl":"/blacksteed","tier":"Novice","tierInt":0,"userId":721076,"userName":"blacksteed"},{"avatarThumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/866788-kg.jpg","displayName":"Nick Brooks","profileUrl":"/nicapotato","tier":"Master","tierInt":3,"userId":866788,"userName":"nicapotato"},{"avatarThumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/1270725-gr.jpg","displayName":"Gabriel Majeri","profileUrl":"/gabrielmajeri","tier":"Novice","tierInt":0,"userId":1270725,"userName":"gabrielmajeri"},{"avatarThumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/1360536-gr.jpg","displayName":"Michal Zurek","profileUrl":"/michal777","tier":"Novice","tierInt":0,"userId":1360536,"userName":"michal777"},{"avatarThumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/1427069-kg.jpg","displayName":"Hiep Nguyen","profileUrl":"/nvhbk16k53","tier":"Contributor","tierInt":1,"userId":1427069,"userName":"nvhbk16k53"},{"avatarThumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/1449054-kg.jpg","displayName":"Akash Ravichandran","profileUrl":"/akashravichandran","tier":"Expert","tierInt":2,"userId":1449054,"userName":"akashravichandran"},{"avatarThumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/1559714-kg.jpg","displayName":"Fazil T","profileUrl":"/fazilbtopal","tier":"Contributor","tierInt":1,"userId":1559714,"userName":"fazilbtopal"},{"avatarThumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/1621143-kg.jpg","displayName":"Nicholas Buhagiar","profileUrl":"/nbuhagiar","tier":"Contributor","tierInt":1,"userId":1621143,"userName":"nbuhagiar"},{"avatarThumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/1758137-kg.png","displayName":"Nitin G","profileUrl":"/nitin194","tier":"Contributor","tierInt":1,"userId":1758137,"userName":"nitin194"},{"avatarThumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/1786637-kg.JPG","displayName":"Baba Firas","profileUrl":"/rinnqd","tier":"Expert","tierInt":2,"userId":1786637,"userName":"rinnqd"},{"avatarThumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/1920655-kg.jpg","displayName":"Heshan Padmasiri","profileUrl":"/heshanpadmasiri","tier":"Novice","tierInt":0,"userId":1920655,"userName":"heshanpadmasiri"},{"avatarThumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/1930894-kg.JPG","displayName":"Eik Schüle","profileUrl":"/rappenlager","tier":"Contributor","tierInt":1,"userId":1930894,"userName":"rappenlager"},{"avatarThumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/default-thumb.png","displayName":"datamafia7","profileUrl":"/datamafia7","tier":"Novice","tierInt":0,"userId":2199585,"userName":"datamafia7"},{"avatarThumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/default-thumb.png","displayName":"Antony Owino","profileUrl":"/ooduor","tier":"Novice","tierInt":0,"userId":2217920,"userName":"ooduor"},{"avatarThumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/2259400-gp.jpg","displayName":"Spartak","profileUrl":"/spartakian","tier":"Novice","tierInt":0,"userId":2259400,"userName":"spartakian"},{"avatarThumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/default-thumb.png","displayName":"Kehan Lyu","profileUrl":"/kehanlyu","tier":"Novice","tierInt":0,"userId":2270791,"userName":"kehanlyu"},{"avatarThumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/2337501-kg.jpg","displayName":"Henry Schroy","profileUrl":"/hschroy","tier":"Contributor","tierInt":1,"userId":2337501,"userName":"hschroy"},{"avatarThumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/2375070-fb.jpg","displayName":"Kacper Kubara","profileUrl":"/kacperkubara","tier":"Contributor","tierInt":1,"userId":2375070,"userName":"kacperkubara"},{"avatarThumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/default-thumb.png","displayName":"FelixMu","profileUrl":"/felixmu","tier":"Contributor","tierInt":1,"userId":2435880,"userName":"felixmu"},{"avatarThumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/2440476-kg.jpeg","displayName":"Pierre-Nicolas Piquin","profileUrl":"/pierrenicolaspiquin","tier":"Contributor","tierInt":1,"userId":2440476,"userName":"pierrenicolaspiquin"},{"avatarThumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/2524628-gr.jpg","displayName":"TerrorTim","profileUrl":"/timjonker","tier":"Novice","tierInt":0,"userId":2524628,"userName":"timjonker"},{"avatarThumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/default-thumb.png","displayName":"Dave","profileUrl":"/b3astly","tier":"Novice","tierInt":0,"userId":2611530,"userName":"b3astly"},{"avatarThumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/default-thumb.png","displayName":"Ganesh MD","profileUrl":"/ganeshmd","tier":"Contributor","tierInt":1,"userId":2869675,"userName":"ganeshmd"},{"avatarThumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/2949675-fb.jpg","displayName":"John Dillenger","profileUrl":"/thorincode","tier":"Novice","tierInt":0,"userId":2949675,"userName":"thorincode"}],"currentUserInfo":{"avatarThumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/868931-kg.jpg","displayName":"folaraz","userName":"folaraz","profileUrl":"/folaraz","tier":"Contributor","tierInt":1,"userId":868931},"showVoters":true,"alwaysShowVoters":true},"parentDataSource":null,"parentName":"multiple data sources","parentUrl":"#data","thumbnailImageUrl":"/static/images/multiple-datasource.png","canWrite":false,"canAdminister":false,"datasetHidden":false,"forkParentIsRedacted":false,"forkDiffLinesChanged":0,"forkDiffLinesDeleted":0,"forkDiffLinesInserted":0,"forkDiffUrl":null,"forkParentAuthorDisplayName":null,"forkParentAuthorUrl":null,"forkParentTitle":null,"forkParentUrl":null,"canSeeDataExplorerV2":true,"canSeeRevampedViewer":true,"canSeeInnerTableOfContents":true,"simplifiedViewer":true,"kernelOutputDataset":null});performance && performance.mark && performance.mark("KernelViewer.componentCouldBootstrap");</script>

<form action="https://www.kaggle.com/colinmorris/exploring-embeddings-with-gensim" id="__AjaxAntiForgeryForm" method="post"><input name="X-XSRF-TOKEN" type="hidden" value="CfDJ8LdUzqlsSWBPr4Ce3rb9VL80BVp_To_mq9CzDdR8l5z2d2SkCEXz7H3HA_CtLKlxkcN45W1H4jGXQ1qXY1GJF-GO0VqN63LfufP-HjA4l6NgBxF1mtt7cz9sRPTJ3QrFTeyXJhq2B21ex8zT48u1P4T3I1IozqiUjE7HdYmyw-fRMg-pra1s1ju1yXpNTmawmA"></form>

<script type="text/x-mathjax-config;executed=true">
    MathJax.Hub.Config({
        "HTML-CSS": {
            preferredFont: "TeX",
            availableFonts: ["STIX", "TeX"],
            linebreaks: {
                automatic: true
            },
            EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50)
        },
        tex2jax: {
            inlineMath: [["\\(", "\\)"], ["\\\\(", "\\\\)"]],
            displayMath: [["$$", "$$"], ["\\[", "\\]"]],
            processEscapes: true,
            ignoreClass: "tex2jax_ignore|dno"
        },
        TeX: {
            noUndefined: {
                attributes: {
                    mathcolor: "red",
                    mathbackground: "#FFEEEE",
                    mathsize: "90%"
                }
            }
        },
        Macros: {
            href: "{}"
        },
        skipStartupTypeset: true,
        messageStyle: "none"
    });
</script>
<script type="text/javascript" async="" crossorigin="anonymous" src="./Exploring Embeddings With Gensim _ Kaggle_files/MathJax.js"></script>



    </div>

        <div class="site-layout__footer">
            <footer class="site-footer">
    <div class="site-footer__content">
        <div class="site-footer__copyright">
            <span>© 2019 Kaggle Inc</span>
        </div>
        <nav class="site-footer__nav">
            <a href="https://www.kaggle.com/team">Our Team</a>
            <a href="https://www.kaggle.com/terms">Terms</a>
            <a href="https://www.kaggle.com/privacy">Privacy</a>
            <a href="https://www.kaggle.com/contact">Contact/Support</a>
        </nav>
        <nav class="site-footer__social">
            <div data-component-name="SocialIcons" style="display: flex; flex-direction: column; flex: 1 0 auto;"><div style="--mdc-theme-on-primary:#fff; --mdc-theme-on-surface:rgba(0, 0, 0, 0.87); --mdc-theme-text-primary-on-background:rgba(0, 0, 0, 0.87); --mdc-theme-text-secondary-on-background:rgba(0, 0, 0, 0.54); --mdc-theme-text-hint-on-background:rgba(0, 0, 0, 0.38); --mdc-theme-text-disabled-on-background:rgba(0, 0, 0, 0.38); --mdc-theme-text-icon-on-background:rgba(0, 0, 0, 0.38); --mdc-theme-primary:#20BEFF; --mdc-theme-error:#F58B8A; --mdc-theme-background:#F8F8F8; --mdc-theme-surface:#F8F8F8; --mdc-theme-primary-bg:#20BEFF; --mdc-theme-secondary-bg:#919294;"><div class="social-icons"><a class="social-icons__link" href="https://www.youtube.com/kaggle" title="Follow Kaggle on YouTube"><i class="fa fa-youtube-square"></i></a><a class="social-icons__link" href="http://www.twitter.com/kaggle" title="Follow Kaggle on Twitter"><i class="fa fa-twitter-square"></i></a><a class="social-icons__link" href="http://www.facebook.com/kaggle" title="Follow Kaggle on Facebook"><i class="fa fa-facebook-square"></i></a><a class="social-icons__link" href="http://www.linkedin.com/company/kaggle" title="Follow Kaggle on LinkedIn"><i class="fa fa-linkedin-square"></i></a></div></div></div><script>var Kaggle=window.Kaggle||{};Kaggle.State=Kaggle.State||[];Kaggle.State.push();performance && performance.mark && performance.mark("SocialIcons.componentCouldBootstrap");</script>
        </nav>
    </div>
</footer>

        </div>
</div>



    <!-- Cheers, web-55955cf5b6-ms2nbp. -->

    </main>


<iframe id="intercom-frame" style="position: absolute !important; opacity: 0 !important; width: 1px !important; height: 1px !important; top: 0 !important; left: 0 !important; border: none !important; display: block !important; z-index: -1 !important;" aria-hidden="true" tabindex="-1" src="./Exploring Embeddings With Gensim _ Kaggle_files/saved_resource.html"></iframe><div id="intercom-css-container"><style data-emotion="intercom-global"></style></div><div id="intercom-container" class="intercom-namespace"><style>html.intercom-mobile-messenger-active,html.intercom-mobile-messenger-active > body,html.intercom-modal-open,#intercom-container-body{overflow:hidden !important;}html.intercom-mobile-messenger-active,html.intercom-mobile-messenger-active > body{position:static !important;}html.intercom-mobile-messenger-active > body{height:0 !important;margin:0 !important;}iframe#intercom-frame{position:absolute !important;opacity:0 !important;width:1px !important;height:1px !important;top:0 !important;left:0 !important;border:none !important;display:block !important;z-index:-1 !important;}</style><div class="intercom-app" aria-live="polite"><div id="intercom-modal-container"></div></div></div></body></html>